{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from src.crosscoder.crosscoder import CrossCoder\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "import einops\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "SMALL_SIZE = 22\n",
    "MEDIUM_SIZE = 24\n",
    "BIGGER_SIZE = 26\n",
    "plt.rc(\"font\", size=SMALL_SIZE, family=\"Times New Roman\")  # controls default text sizes\n",
    "plt.rc(\n",
    "    \"axes\", titlesize=BIGGER_SIZE, labelsize=MEDIUM_SIZE\n",
    ")  # fontsize of the axes title\n",
    "plt.rc(\"axes\", labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
    "plt.rc(\"xtick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
    "plt.rc(\"ytick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
    "plt.rc(\"legend\", fontsize=SMALL_SIZE)  # legend fontsize\n",
    "plt.rc(\"figure\", titlesize=BIGGER_SIZE, labelsize=SMALL_SIZE)  # f\n",
    "\n",
    "colors = [\"#386EC2\", \"#B5B5B2\", \"#990006\", \"#625D0A\", \"#B9741F\", \"#213958\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float16\n",
    "ckpt_path = \"/home/bcywinski/code/diffing/sae-ckpts/crosscoder-sdxl/expansion_factor4_l120.0_dec_init_norm0.1_4_steps\"\n",
    "hookpoint = \"down_blocks.2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosscoder = CrossCoder.load_from_disk(\n",
    "    os.path.join(\n",
    "        ckpt_path,\n",
    "        hookpoint,\n",
    "    ),\n",
    "    device=\"cuda\",\n",
    ").to(dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/data/SHARE/datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_dataset_path = \"/data/bcywinski/activations/coco2017/sdxl_4/output/\"\n",
    "model2_dataset_path = \"/data/bcywinski/activations/coco2017/sdxl-turbo/output/\"\n",
    "model1_num_timesteps = 4\n",
    "model2_num_timesteps = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.scripts.train_crosscoder import PairedDataset\n",
    "\n",
    "model1_dataset = Dataset.load_from_disk(\n",
    "    os.path.join(model1_dataset_path, hookpoint), keep_in_memory=False\n",
    ")\n",
    "model2_dataset = Dataset.load_from_disk(\n",
    "    os.path.join(model2_dataset_path, hookpoint), keep_in_memory=False\n",
    ")\n",
    "model1_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"activations\", \"timestep\", \"file_name\"], dtype=dtype\n",
    ")\n",
    "model2_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"activations\", \"timestep\", \"file_name\"], dtype=dtype\n",
    ")\n",
    "\n",
    "\n",
    "paired_dataset = PairedDataset(\n",
    "    model1_dataset,\n",
    "    model2_dataset,\n",
    "    100,\n",
    "    True,\n",
    "    model1_num_timesteps,\n",
    "    model2_num_timesteps,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_activations_per_sample1 = torch.zeros(\n",
    "    (len(paired_dataset), crosscoder.num_latents), dtype=torch.float16\n",
    ")\n",
    "batch_size = 16\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    paired_dataset, batch_size=16, shuffle=False, num_workers=4\n",
    ")\n",
    "for i, batch in tqdm(enumerate(dl), total=len(dl)):\n",
    "    acts = batch[\"model1\"]\n",
    "    acts = acts.to(crosscoder.W_dec.device)\n",
    "    acts = einops.rearrange(\n",
    "        acts,\n",
    "        \"batch sample_size d_model -> (batch sample_size) d_model\",\n",
    "    )\n",
    "    out = einops.einsum(\n",
    "        acts,\n",
    "        crosscoder.W_enc[0],\n",
    "        \"batch d_model, d_model d_latent -> batch d_latent\",\n",
    "    )\n",
    "    out = torch.nn.functional.relu(out + crosscoder.b_enc[0])\n",
    "    # Reshape to get per-sample activations and compute mean for each sample\n",
    "    out = out.view(\n",
    "        batch[\"model1\"].shape[0], -1, crosscoder.num_latents\n",
    "    )  # [batch, sample_size, num_latents]\n",
    "    batch_avg_activations = out.mean(dim=1).to(\n",
    "        dtype=torch.float16\n",
    "    )  # [batch, num_latents]\n",
    "\n",
    "    # Store in the correct indices\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min(start_idx + batch_size, len(paired_dataset))\n",
    "    avg_activations_per_sample1[start_idx:end_idx] = batch_avg_activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_topk_activating_examples(activations_per_sample, latent_idx, k=10):\n",
    "    topk_indices = torch.argsort(\n",
    "        activations_per_sample[:, latent_idx], dim=0, descending=True\n",
    "    )[:k]\n",
    "    return topk_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_idx = 2735\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "topk_indices1 = find_topk_activating_examples(\n",
    "    avg_activations_per_sample1, latent_idx, k\n",
    ")  # find topk samples containing patches with higest activations\n",
    "topk_samples1 = paired_dataset[topk_indices1.tolist()]\n",
    "sae_latents1 = []\n",
    "activations1 = topk_samples1[\"model1\"]\n",
    "timesteps1 = topk_samples1[\"model1_timestep\"]\n",
    "file_names_topk1 = topk_samples1[\"file_name\"]\n",
    "activations1 = einops.rearrange(\n",
    "    activations1,\n",
    "    \"batch sample_size d_model -> (batch sample_size) d_model\",\n",
    ")\n",
    "activations1 = activations1.to(crosscoder.W_dec.device)\n",
    "out = einops.einsum(\n",
    "    activations1,\n",
    "    crosscoder.W_enc[0],\n",
    "    \"batch d_model, d_model d_latent -> batch d_latent\",\n",
    ")\n",
    "out = torch.nn.functional.relu(out + crosscoder.b_enc[0])\n",
    "sae_latents1 = out.view(k, -1, crosscoder.num_latents)\n",
    "sae_latents1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, len(topk_indices1), figsize=(18, 6))\n",
    "\n",
    "# Plot max activating examples in two rows:\n",
    "# Row 1: Original images from Model 1\n",
    "# Row 2: Model 1 activations\n",
    "for i in range(len(topk_indices1)):\n",
    "    # Model 1 images\n",
    "    img1 = Image.open(os.path.join(dataset_path, file_names_topk1[i]))\n",
    "    img1 = img1.resize((512, 512))\n",
    "    img1 = img1.convert(\"RGB\")\n",
    "\n",
    "    # Process activations for model 1\n",
    "    sae_latent_activations1 = sae_latents1[i].reshape(\n",
    "        int(torch.sqrt(torch.tensor(sae_latents1.shape[1])).item()),\n",
    "        int(torch.sqrt(torch.tensor(sae_latents1.shape[1])).item()),\n",
    "        -1,\n",
    "    )[:, :, latent_idx]\n",
    "    # Convert latent activations to numpy and normalize\n",
    "    activation_map1 = sae_latent_activations1[:, :].detach().cpu().numpy()\n",
    "    activation_map1 = (activation_map1 - activation_map1.min()) / (\n",
    "        activation_map1.max() - activation_map1.min() + 1e-8\n",
    "    )\n",
    "\n",
    "    # Calculate upscale factor to match image size for model 1\n",
    "    patch_size1 = 512 // activation_map1.shape[0]\n",
    "    activation_map1 = np.kron(activation_map1, np.ones((patch_size1, patch_size1)))\n",
    "\n",
    "    # Create heatmap overlays\n",
    "    heatmap1 = np.uint8(plt.cm.jet(activation_map1)[..., :3] * 255)\n",
    "    heatmap1 = Image.fromarray(heatmap1)\n",
    "\n",
    "    # Blend original images with heatmaps\n",
    "    blended_img1 = Image.blend(img1, heatmap1, alpha=0.4)\n",
    "\n",
    "    # Calculate average activation for the image\n",
    "    avg_activation = sae_latent_activations1.mean().item()\n",
    "\n",
    "    # Row 1: Original images\n",
    "    axes[0, i].imshow(img1)\n",
    "    axes[0, i].axis(\"off\")\n",
    "    axes[0, i].set_title(\n",
    "        f\"Activation: {avg_activation:.2f}\\nTimestep: {int(timesteps1[i].item())}\",\n",
    "        fontsize=SMALL_SIZE,\n",
    "    )\n",
    "    if i == 0:\n",
    "        axes[0, 0].set_ylabel(\"Original Images\", fontsize=SMALL_SIZE)\n",
    "\n",
    "    # Row 2: Activations\n",
    "    axes[1, i].imshow(blended_img1)\n",
    "    axes[1, i].axis(\"off\")\n",
    "    if i == 0:\n",
    "        axes[1, 0].set_ylabel(\"Activations\", fontsize=SMALL_SIZE)\n",
    "\n",
    "plt.suptitle(f\"Max Activating Examples for Neuron {latent_idx}\", fontsize=BIGGER_SIZE)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure l0 of latent space on whole dataset\n",
    "# Calculate L0 sparsity across the whole dataset\n",
    "def calculate_average_l0(dataloader, threshold=0.0):\n",
    "    \"\"\"\n",
    "    Calculate the average L0 sparsity (number of active neurons) in latent space\n",
    "\n",
    "    Args:\n",
    "        dataloader: DataLoader containing the dataset\n",
    "        threshold: Activation threshold (neurons with activation > threshold are considered active)\n",
    "\n",
    "    Returns:\n",
    "        average_l0: Average number of active neurons per sample\n",
    "        l0_per_sample: Array of L0 values for each sample\n",
    "    \"\"\"\n",
    "    l0_per_sample = []\n",
    "    total_samples = 0\n",
    "    neuron_activated_number = torch.zeros(crosscoder.num_latents)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Calculating L0 sparsity\"):\n",
    "            acts = batch[\"model1\"]\n",
    "            acts = acts.to(crosscoder.W_dec.device)\n",
    "            acts = einops.rearrange(\n",
    "                acts,\n",
    "                \"batch sample_size d_model -> (batch sample_size) d_model\",\n",
    "            )\n",
    "\n",
    "            # Encode to latent space\n",
    "            latents = einops.einsum(\n",
    "                acts,\n",
    "                crosscoder.W_enc[0],\n",
    "                \"batch d_model, d_model d_latent -> batch d_latent\",\n",
    "            )\n",
    "            latents = torch.nn.functional.relu(latents + crosscoder.b_enc[0])\n",
    "            neuron_activated_number += (latents > threshold).sum(dim=0).cpu()\n",
    "\n",
    "            # Count active neurons (L0 norm)\n",
    "            active_neurons = (latents > threshold).sum(dim=1)\n",
    "\n",
    "            # Store L0 values\n",
    "            l0_per_sample.extend(active_neurons.cpu().tolist())\n",
    "            total_samples += latents.shape[0]\n",
    "\n",
    "    l0_per_sample = np.array(l0_per_sample)\n",
    "    average_l0 = l0_per_sample.mean()\n",
    "\n",
    "    return average_l0, l0_per_sample, neuron_activated_number\n",
    "\n",
    "\n",
    "# Calculate for the whole dataset with a minimal threshold\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    paired_dataset, batch_size=16, shuffle=False, num_workers=4\n",
    ")\n",
    "avg_l0, l0_values, neuron_activated_number = calculate_average_l0(dl, threshold=0.01)\n",
    "print(\n",
    "    f\"Average L0 sparsity (active neurons): {avg_l0:.2f} out of {crosscoder.num_latents}\"\n",
    ")\n",
    "print(f\"Average L0 percent: {100 * avg_l0 / crosscoder.num_latents:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of L0 values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(l0_values, bins=50, alpha=0.7)\n",
    "plt.axvline(\n",
    "    avg_l0,\n",
    "    color=\"blue\",\n",
    "    linestyle=\"dashed\",\n",
    "    linewidth=2,\n",
    "    label=f\"Avg: {avg_l0:.2f}\",\n",
    ")\n",
    "plt.xlabel(\"Number of Active Neurons\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"L0 of Latent Space - Base Model\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep_map = [\n",
    "    model1_dataset[0][\"timestep\"].item(),\n",
    "    model1_dataset[1][\"timestep\"].item(),\n",
    "    model1_dataset[2][\"timestep\"].item(),\n",
    "    model1_dataset[3][\"timestep\"].item(),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 4 histograms of L0 values, sampling every 256th value with different offsets\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Create 4 histograms with different starting points\n",
    "for i, start in enumerate([0, 1, 2, 3]):\n",
    "    # Select every 256th value starting from 'start'\n",
    "    l0_subset = l0_values.reshape(len(model1_dataset), 256)[start::4].flatten()\n",
    "    print(l0_subset.shape)\n",
    "\n",
    "    # Plot histogram\n",
    "    axes[i].hist(l0_subset, bins=50, alpha=0.7, color=f\"C{i}\")\n",
    "\n",
    "    # Add mean line\n",
    "    subset_mean = l0_subset.mean()\n",
    "    axes[i].axvline(\n",
    "        subset_mean,\n",
    "        color=\"red\",\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=2,\n",
    "        label=f\"Avg: {subset_mean:.2f}\",\n",
    "    )\n",
    "\n",
    "    # Calculate and display percentages\n",
    "    subset_percent = 100 * subset_mean / crosscoder.num_latents\n",
    "\n",
    "    axes[i].set_xlabel(\"Number of Active Neurons\")\n",
    "    axes[i].set_ylabel(\"Count\")\n",
    "    axes[i].set_title(f\"L0 timestep {int(timestep_map[start])}\")\n",
    "\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.suptitle(\"L0 across timesteps - Base Model\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average L0 for each timestep\n",
    "timestep_averages = []\n",
    "timestep_percentages = []\n",
    "\n",
    "\n",
    "# Create 4 subsets with different starting points (corresponding to different timesteps)\n",
    "for i, start in enumerate([0, 1, 2, 3]):\n",
    "    # Select values for this timestep (every 4th sample starting from the offset)\n",
    "    l0_subset = l0_values.reshape(len(model1_dataset), 256)[start::4].flatten()\n",
    "\n",
    "    # Calculate average L0 for this timestep\n",
    "    avg_l0_timestep = l0_subset.mean()\n",
    "    timestep_averages.append(avg_l0_timestep)\n",
    "\n",
    "    # Calculate percentage of active neurons\n",
    "    percent_active = 100 * avg_l0_timestep / crosscoder.num_latents\n",
    "    timestep_percentages.append(percent_active)\n",
    "\n",
    "# Create bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Use the timestep_map to get actual timestep values for x-axis labels\n",
    "x_labels = [f\"Timestep {int(timestep_map[i])}\" for i in range(4)]\n",
    "bars = plt.bar(x_labels, timestep_averages, color=colors[:4])\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 5,  # Small offset above the bar\n",
    "        f\"{height:.1f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "plt.title(\"Average Number of Active Neurons by Timestep - Base Model\")\n",
    "plt.ylabel(\"Average L0 (Active Neurons)\")\n",
    "plt.ylim(0, 100)\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep_averages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep_averages2 = [\n",
    "    np.float64(3.3881645833333334),\n",
    "    np.float64(10.302678776041667),\n",
    "    np.float64(29.474933463541667),\n",
    "    np.float64(53.709834244791665),\n",
    "]\n",
    "# Create bar plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Use the timestep_map to get actual timestep values for x-axis labels\n",
    "x_labels = [f\"Timestep {int(timestep_map[i])}\" for i in range(4)]\n",
    "\n",
    "# Set width and positions for the bars\n",
    "bar_width = 0.35\n",
    "x_positions = np.arange(len(x_labels))\n",
    "\n",
    "# Create grouped bars for both sets of averages - use single colors for each group\n",
    "bars1 = plt.bar(\n",
    "    x_positions - bar_width / 2,\n",
    "    timestep_averages,\n",
    "    bar_width,\n",
    "    color=colors[1],  # Single blue color for all left bars\n",
    "    label=\"Base Model\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "bars2 = plt.bar(\n",
    "    x_positions + bar_width / 2,\n",
    "    timestep_averages2,\n",
    "    bar_width,\n",
    "    color=colors[-2],  # Single red color for all right bars\n",
    "    label=\"Distilled Model\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2.0,\n",
    "            height + 2,  # Small offset above the bar\n",
    "            f\"{height:.1f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "\n",
    "plt.title(\"Average Number of Active Neurons per Timestep\")\n",
    "plt.ylabel(\"Average L0 (Active Neurons)\")\n",
    "plt.ylim(0, 60)\n",
    "plt.grid(axis=\"y\", alpha=0.25, linestyle=\"--\")\n",
    "plt.xticks(x_positions, x_labels)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/l0_timesteps.pdf\", dpi=300, format=\"pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_activated_number.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = crosscoder.W_dec.norm(dim=-1).cpu()\n",
    "relative_norms = norms[:, 1] / norms.sum(dim=-1)\n",
    "only_base_features_mask = relative_norms < 0.25\n",
    "only_turbo_features_mask = relative_norms > 0.75\n",
    "shared_features_mask = (relative_norms >= 0.25) & (relative_norms <= 0.75)\n",
    "only_base_features_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average number of activated neurons for base and turbo features\n",
    "base_activated = neuron_activated_number[only_base_features_mask].mean().item()\n",
    "turbo_activated = neuron_activated_number[only_turbo_features_mask].mean().item()\n",
    "shared_activated = neuron_activated_number[shared_features_mask].mean().item()\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "categories = [\"Base\", \"Shared\", \"Distilled\"]\n",
    "values = [base_activated, shared_activated, turbo_activated]\n",
    "colors = [\"#3498db\", \"#2ecc71\", \"#e74c3c\"]\n",
    "\n",
    "bars = plt.bar(categories, values, color=colors)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 0.01,  # Reduced offset to avoid warning\n",
    "        f\"{height:.4f}\",  # Increased precision for small values\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "plt.title(\"Average Number of Times a Neuron Fired - Base Model\")\n",
    "plt.ylim(0, 800000)  # Set y-limit with appropriate headroom\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout(pad=1.1)  # Added padding to avoid tight layout warning\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of activated neurons from base, shared, and distilled groups per timestep for both models\n",
    "def plot_activated_neurons_by_group_both_models(threshold=0.0):\n",
    "    print(\"Analyzing activated neurons by group and timestep for both models...\")\n",
    "\n",
    "    # Store counts for each group by timestep for both models\n",
    "    model1_activated_counts = {\n",
    "        ts: {\"base\": 0, \"shared\": 0, \"distilled\": 0, \"samples\": 0}\n",
    "        for ts in timestep_map\n",
    "    }\n",
    "\n",
    "    model2_activated_counts = {\n",
    "        ts: {\"base\": 0, \"shared\": 0, \"distilled\": 0, \"samples\": 0}\n",
    "        for ts in timestep_map\n",
    "    }\n",
    "\n",
    "    # Create dataloader for batch processing\n",
    "    dl = torch.utils.data.DataLoader(\n",
    "        paired_dataset, batch_size=16, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "    # Process dataset in batches\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dl, desc=\"Processing samples\"):\n",
    "            # Process base model activations (model1)\n",
    "            acts_model1 = batch[\"model1\"]\n",
    "            timesteps_model1 = batch[\"model1_timestep\"]\n",
    "\n",
    "            # Process distilled model activations (model2)\n",
    "            acts_model2 = batch[\"model2\"]\n",
    "            timesteps_model2 = batch[\"model2_timestep\"]\n",
    "\n",
    "            # Analyze each sample in model1\n",
    "            for i in range(acts_model1.shape[0]):\n",
    "                ts = int(timesteps_model1[i].item())\n",
    "                if ts not in model1_activated_counts:\n",
    "                    continue\n",
    "\n",
    "                # Get activations for this sample\n",
    "                act = acts_model1[i : i + 1].to(\n",
    "                    crosscoder.W_dec.device\n",
    "                )  # Add batch dimension\n",
    "\n",
    "                # Process through encoder\n",
    "                act = act.reshape(\n",
    "                    -1, act.shape[-1]\n",
    "                )  # Reshape to [batch*spatial, d_model]\n",
    "\n",
    "                # Get latent activations using model1 encoder\n",
    "                latents = einops.einsum(\n",
    "                    act,\n",
    "                    crosscoder.W_enc[0],\n",
    "                    \"batch d_model, d_model d_latent -> batch d_latent\",\n",
    "                )\n",
    "                latents = torch.nn.functional.relu(latents + crosscoder.b_enc[0])\n",
    "\n",
    "                # Count activated neurons at each spatial position\n",
    "                activated_per_position = (latents > threshold).float().cpu()\n",
    "\n",
    "                # Count across all spatial positions for each neuron type\n",
    "                base_activated = (\n",
    "                    activated_per_position[:, only_base_features_mask].sum(dim=1).mean()\n",
    "                ).item()\n",
    "                shared_activated = (\n",
    "                    activated_per_position[:, shared_features_mask].sum(dim=1).mean()\n",
    "                ).item()\n",
    "                distilled_activated = (\n",
    "                    activated_per_position[:, only_turbo_features_mask]\n",
    "                    .sum(dim=1)\n",
    "                    .mean()\n",
    "                ).item()\n",
    "\n",
    "                # Add to counts\n",
    "                model1_activated_counts[ts][\"base\"] += base_activated\n",
    "                model1_activated_counts[ts][\"shared\"] += shared_activated\n",
    "                model1_activated_counts[ts][\"distilled\"] += distilled_activated\n",
    "                model1_activated_counts[ts][\"samples\"] += 1\n",
    "\n",
    "            # Analyze each sample in model2\n",
    "            for i in range(acts_model2.shape[0]):\n",
    "                ts = int(timesteps_model2[i].item())\n",
    "                if ts not in model2_activated_counts:\n",
    "                    continue\n",
    "\n",
    "                # Get activations for this sample\n",
    "                act = acts_model2[i : i + 1].to(\n",
    "                    crosscoder.W_dec.device\n",
    "                )  # Add batch dimension\n",
    "\n",
    "                # Process through encoder\n",
    "                act = act.reshape(\n",
    "                    -1, act.shape[-1]\n",
    "                )  # Reshape to [batch*spatial, d_model]\n",
    "\n",
    "                # Get latent activations using model2 encoder\n",
    "                latents = einops.einsum(\n",
    "                    act,\n",
    "                    crosscoder.W_enc[1],  # Use model2 encoder weights\n",
    "                    \"batch d_model, d_model d_latent -> batch d_latent\",\n",
    "                )\n",
    "                latents = torch.nn.functional.relu(\n",
    "                    latents + crosscoder.b_enc[1]\n",
    "                )  # Use model2 bias\n",
    "\n",
    "                # Count activated neurons at each spatial position\n",
    "                activated_per_position = (latents > threshold).float().cpu()\n",
    "\n",
    "                # Count across all spatial positions for each neuron type\n",
    "                base_activated = (\n",
    "                    activated_per_position[:, only_base_features_mask].sum(dim=1).mean()\n",
    "                ).item()\n",
    "                shared_activated = (\n",
    "                    activated_per_position[:, shared_features_mask].sum(dim=1).mean()\n",
    "                ).item()\n",
    "                distilled_activated = (\n",
    "                    activated_per_position[:, only_turbo_features_mask]\n",
    "                    .sum(dim=1)\n",
    "                    .mean()\n",
    "                ).item()\n",
    "\n",
    "                # Add to counts\n",
    "                model2_activated_counts[ts][\"base\"] += base_activated\n",
    "                model2_activated_counts[ts][\"shared\"] += shared_activated\n",
    "                model2_activated_counts[ts][\"distilled\"] += distilled_activated\n",
    "                model2_activated_counts[ts][\"samples\"] += 1\n",
    "\n",
    "    # Calculate averages for model1\n",
    "    model1_timesteps = []\n",
    "    model1_base_counts = []\n",
    "    model1_shared_counts = []\n",
    "    model1_distilled_counts = []\n",
    "\n",
    "    for ts in sorted(model1_activated_counts.keys()):\n",
    "        if model1_activated_counts[ts][\"samples\"] > 0:\n",
    "            model1_timesteps.append(ts)\n",
    "            model1_base_counts.append(\n",
    "                model1_activated_counts[ts][\"base\"]\n",
    "                / model1_activated_counts[ts][\"samples\"]\n",
    "            )\n",
    "            model1_shared_counts.append(\n",
    "                model1_activated_counts[ts][\"shared\"]\n",
    "                / model1_activated_counts[ts][\"samples\"]\n",
    "            )\n",
    "            model1_distilled_counts.append(\n",
    "                model1_activated_counts[ts][\"distilled\"]\n",
    "                / model1_activated_counts[ts][\"samples\"]\n",
    "            )\n",
    "\n",
    "    # Calculate averages for model2\n",
    "    model2_timesteps = []\n",
    "    model2_base_counts = []\n",
    "    model2_shared_counts = []\n",
    "    model2_distilled_counts = []\n",
    "\n",
    "    for ts in sorted(model2_activated_counts.keys()):\n",
    "        if model2_activated_counts[ts][\"samples\"] > 0:\n",
    "            model2_timesteps.append(ts)\n",
    "            model2_base_counts.append(\n",
    "                model2_activated_counts[ts][\"base\"]\n",
    "                / model2_activated_counts[ts][\"samples\"]\n",
    "            )\n",
    "            model2_shared_counts.append(\n",
    "                model2_activated_counts[ts][\"shared\"]\n",
    "                / model2_activated_counts[ts][\"samples\"]\n",
    "            )\n",
    "            model2_distilled_counts.append(\n",
    "                model2_activated_counts[ts][\"distilled\"]\n",
    "                / model2_activated_counts[ts][\"samples\"]\n",
    "            )\n",
    "\n",
    "    # Create figure with subplots for both models\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "    # Model 1 (Base Model) - Stacked bar chart\n",
    "    x1 = np.arange(len(model1_timesteps))\n",
    "    width = 0.6\n",
    "\n",
    "    # Create stacked bars for model1\n",
    "    ax1.bar(x1, model1_base_counts, width, label=\"Base-specific\", color=colors[0])\n",
    "    ax1.bar(\n",
    "        x1,\n",
    "        model1_shared_counts,\n",
    "        width,\n",
    "        bottom=model1_base_counts,\n",
    "        label=\"Shared\",\n",
    "        color=colors[1],\n",
    "    )\n",
    "\n",
    "    # Calculate total heights for adding the distilled bars\n",
    "    model1_bottoms = [b + s for b, s in zip(model1_base_counts, model1_shared_counts)]\n",
    "    ax1.bar(\n",
    "        x1,\n",
    "        model1_distilled_counts,\n",
    "        width,\n",
    "        bottom=model1_bottoms,\n",
    "        label=\"Distilled-specific\",\n",
    "        color=colors[2],\n",
    "    )\n",
    "\n",
    "    # Add text annotations for model1\n",
    "    for i in range(len(x1)):\n",
    "        # Base count (middle of segment)\n",
    "        if model1_base_counts[i] > 0.5:\n",
    "            ax1.text(\n",
    "                x1[i],\n",
    "                model1_base_counts[i] / 2,\n",
    "                f\"{model1_base_counts[i]:.1f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"white\",\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "        # Shared count (middle of segment)\n",
    "        if model1_shared_counts[i] > 0.5:\n",
    "            ax1.text(\n",
    "                x1[i],\n",
    "                model1_base_counts[i] + model1_shared_counts[i] / 2,\n",
    "                f\"{model1_shared_counts[i]:.1f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"black\",\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "        # Distilled count (middle of segment)\n",
    "        if model1_distilled_counts[i] > 0.5:\n",
    "            ax1.text(\n",
    "                x1[i],\n",
    "                model1_bottoms[i] + model1_distilled_counts[i] / 2,\n",
    "                f\"{model1_distilled_counts[i]:.1f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"white\",\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "        # Total count (on top)\n",
    "        total = (\n",
    "            model1_base_counts[i] + model1_shared_counts[i] + model1_distilled_counts[i]\n",
    "        )\n",
    "        ax1.text(\n",
    "            x1[i],\n",
    "            model1_bottoms[i] + model1_distilled_counts[i] + 0.5,\n",
    "            f\"Total: {total:.1f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "    # Add model1 sample counts below x-axis\n",
    "    for i, ts in enumerate(model1_timesteps):\n",
    "        ax1.text(\n",
    "            i,\n",
    "            -1.5,\n",
    "            f\"n={model1_activated_counts[ts]['samples']}\",\n",
    "            ha=\"center\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "    ax1.set_xlabel(\"Timestep\")\n",
    "    ax1.set_ylabel(\"Average Number of Activated Neurons\")\n",
    "    ax1.set_title(\"Base Model - Average Activated Neurons by Group\")\n",
    "    ax1.set_xticks(x1)\n",
    "    ax1.set_xticklabels([str(ts) for ts in model1_timesteps])\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "    # Model 2 (Distilled Model) - Stacked bar chart\n",
    "    x2 = np.arange(len(model2_timesteps))\n",
    "\n",
    "    # Create stacked bars for model2\n",
    "    ax2.bar(x2, model2_base_counts, width, label=\"Base-specific\", color=colors[0])\n",
    "    ax2.bar(\n",
    "        x2,\n",
    "        model2_shared_counts,\n",
    "        width,\n",
    "        bottom=model2_base_counts,\n",
    "        label=\"Shared\",\n",
    "        color=colors[1],\n",
    "    )\n",
    "\n",
    "    # Calculate total heights for adding the distilled bars\n",
    "    model2_bottoms = [b + s for b, s in zip(model2_base_counts, model2_shared_counts)]\n",
    "    ax2.bar(\n",
    "        x2,\n",
    "        model2_distilled_counts,\n",
    "        width,\n",
    "        bottom=model2_bottoms,\n",
    "        label=\"Distilled-specific\",\n",
    "        color=colors[2],\n",
    "    )\n",
    "\n",
    "    # Add text annotations for model2\n",
    "    for i in range(len(x2)):\n",
    "        # Base count (middle of segment)\n",
    "        if model2_base_counts[i] > 0.5:\n",
    "            ax2.text(\n",
    "                x2[i],\n",
    "                model2_base_counts[i] / 2,\n",
    "                f\"{model2_base_counts[i]:.1f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"white\",\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "        # Shared count (middle of segment)\n",
    "        if model2_shared_counts[i] > 0.5:\n",
    "            ax2.text(\n",
    "                x2[i],\n",
    "                model2_base_counts[i] + model2_shared_counts[i] / 2,\n",
    "                f\"{model2_shared_counts[i]:.1f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"black\",\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "        # Distilled count (middle of segment)\n",
    "        if model2_distilled_counts[i] > 0.5:\n",
    "            ax2.text(\n",
    "                x2[i],\n",
    "                model2_bottoms[i] + model2_distilled_counts[i] / 2,\n",
    "                f\"{model2_distilled_counts[i]:.1f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"white\",\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "        # Total count (on top)\n",
    "        total = (\n",
    "            model2_base_counts[i] + model2_shared_counts[i] + model2_distilled_counts[i]\n",
    "        )\n",
    "        ax2.text(\n",
    "            x2[i],\n",
    "            model2_bottoms[i] + model2_distilled_counts[i] + 0.5,\n",
    "            f\"Total: {total:.1f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "    # Add model2 sample counts below x-axis\n",
    "    for i, ts in enumerate(model2_timesteps):\n",
    "        ax2.text(\n",
    "            i,\n",
    "            -1.5,\n",
    "            f\"n={model2_activated_counts[ts]['samples']}\",\n",
    "            ha=\"center\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "    ax2.set_xlabel(\"Timestep\")\n",
    "    ax2.set_ylabel(\"Average Number of Activated Neurons\")\n",
    "    ax2.set_title(\"Distilled Model - Average Activated Neurons by Group\")\n",
    "    ax2.set_xticks(x2)\n",
    "    ax2.set_xticklabels([str(ts) for ts in model2_timesteps])\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    ax2.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "    plt.suptitle(\n",
    "        \"Comparison of Activated Neurons by Group and Timestep\", fontsize=BIGGER_SIZE\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        \"figures/activated_neurons_by_group_both_models.pdf\",\n",
    "        dpi=300,\n",
    "        format=\"pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "\n",
    "    # Also create a plot comparing total activations between models\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Prepare data\n",
    "    common_timesteps = sorted(set(model1_timesteps).intersection(set(model2_timesteps)))\n",
    "\n",
    "    model1_totals = []\n",
    "    model2_totals = []\n",
    "\n",
    "    for ts in common_timesteps:\n",
    "        idx1 = model1_timesteps.index(ts)\n",
    "        idx2 = model2_timesteps.index(ts)\n",
    "\n",
    "        model1_total = (\n",
    "            model1_base_counts[idx1]\n",
    "            + model1_shared_counts[idx1]\n",
    "            + model1_distilled_counts[idx1]\n",
    "        )\n",
    "        model2_total = (\n",
    "            model2_base_counts[idx2]\n",
    "            + model2_shared_counts[idx2]\n",
    "            + model2_distilled_counts[idx2]\n",
    "        )\n",
    "\n",
    "        model1_totals.append(model1_total)\n",
    "        model2_totals.append(model2_total)\n",
    "\n",
    "    # Create grouped bar chart\n",
    "    x = np.arange(len(common_timesteps))\n",
    "    width = 0.35\n",
    "\n",
    "    plt.bar(x - width / 2, model1_totals, width, label=\"Base Model\", color=colors[0])\n",
    "    plt.bar(\n",
    "        x + width / 2, model2_totals, width, label=\"Distilled Model\", color=colors[2]\n",
    "    )\n",
    "\n",
    "    # Add annotations\n",
    "    for i in range(len(x)):\n",
    "        plt.text(\n",
    "            x[i] - width / 2,\n",
    "            model1_totals[i] + 0.5,\n",
    "            f\"{model1_totals[i]:.1f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "        plt.text(\n",
    "            x[i] + width / 2,\n",
    "            model2_totals[i] + 0.5,\n",
    "            f\"{model2_totals[i]:.1f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Timestep\")\n",
    "    plt.ylabel(\"Average Number of Activated Neurons\")\n",
    "    plt.title(\"Total Activated Neurons Comparison\")\n",
    "    plt.xticks(x, [str(ts) for ts in common_timesteps])\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        \"figures/total_activated_neurons_comparison.pdf\",\n",
    "        dpi=300,\n",
    "        format=\"pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "\n",
    "    return {\"model1\": model1_activated_counts, \"model2\": model2_activated_counts}\n",
    "\n",
    "\n",
    "# Run the function\n",
    "activated_neurons_data_both_models = plot_activated_neurons_by_group_both_models(\n",
    "    threshold=0.01\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of activated neurons from base, shared, and distilled groups per timestep for both models\n",
    "def plot_activated_neurons_by_group_both_models(threshold=0.0):\n",
    "    print(\"Analyzing activated neurons by group and timestep for both models...\")\n",
    "\n",
    "    # Store counts for each group by timestep for both models\n",
    "    model1_activated_counts = {\n",
    "        ts: {\"base\": 0, \"shared\": 0, \"distilled\": 0, \"samples\": 0}\n",
    "        for ts in timestep_map\n",
    "    }\n",
    "\n",
    "    model2_activated_counts = {\n",
    "        ts: {\"base\": 0, \"shared\": 0, \"distilled\": 0, \"samples\": 0}\n",
    "        for ts in timestep_map\n",
    "    }\n",
    "\n",
    "    # Create dataloader for batch processing\n",
    "    dl = torch.utils.data.DataLoader(\n",
    "        paired_dataset, batch_size=16, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "    # Process dataset in batches\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dl, desc=\"Processing samples\"):\n",
    "            # Process base model activations (model1)\n",
    "            acts_model1 = batch[\"model1\"]\n",
    "            timesteps_model1 = batch[\"model1_timestep\"]\n",
    "\n",
    "            # Process distilled model activations (model2)\n",
    "            acts_model2 = batch[\"model2\"]\n",
    "            timesteps_model2 = batch[\"model2_timestep\"]\n",
    "\n",
    "            # Analyze each sample in model1\n",
    "            for i in range(acts_model1.shape[0]):\n",
    "                ts = int(timesteps_model1[i].item())\n",
    "                if ts not in model1_activated_counts:\n",
    "                    continue\n",
    "\n",
    "                # Get activations for this sample\n",
    "                act = acts_model1[i : i + 1].to(\n",
    "                    crosscoder.W_dec.device\n",
    "                )  # Add batch dimension\n",
    "\n",
    "                # Process through encoder\n",
    "                act = act.reshape(\n",
    "                    -1, act.shape[-1]\n",
    "                )  # Reshape to [batch*spatial, d_model]\n",
    "\n",
    "                # Get latent activations using model1 encoder\n",
    "                latents = einops.einsum(\n",
    "                    act,\n",
    "                    crosscoder.W_enc[0],\n",
    "                    \"batch d_model, d_model d_latent -> batch d_latent\",\n",
    "                )\n",
    "                latents = torch.nn.functional.relu(latents + crosscoder.b_enc[0])\n",
    "\n",
    "                # Count activated neurons at each spatial position\n",
    "                activated_per_position = (latents > threshold).float().cpu()\n",
    "\n",
    "                # Count across all spatial positions for each neuron type\n",
    "                base_activated = (\n",
    "                    activated_per_position[:, only_base_features_mask].sum(dim=1).mean()\n",
    "                ).item()\n",
    "                shared_activated = (\n",
    "                    activated_per_position[:, shared_features_mask].sum(dim=1).mean()\n",
    "                ).item()\n",
    "                distilled_activated = (\n",
    "                    activated_per_position[:, only_turbo_features_mask]\n",
    "                    .sum(dim=1)\n",
    "                    .mean()\n",
    "                ).item()\n",
    "\n",
    "                # Add to counts\n",
    "                model1_activated_counts[ts][\"base\"] += base_activated\n",
    "                model1_activated_counts[ts][\"shared\"] += shared_activated\n",
    "                model1_activated_counts[ts][\"distilled\"] += distilled_activated\n",
    "                model1_activated_counts[ts][\"samples\"] += 1\n",
    "\n",
    "            # Analyze each sample in model2\n",
    "            for i in range(acts_model2.shape[0]):\n",
    "                ts = int(timesteps_model2[i].item())\n",
    "                if ts not in model2_activated_counts:\n",
    "                    continue\n",
    "\n",
    "                # Get activations for this sample\n",
    "                act = acts_model2[i : i + 1].to(\n",
    "                    crosscoder.W_dec.device\n",
    "                )  # Add batch dimension\n",
    "\n",
    "                # Process through encoder\n",
    "                act = act.reshape(\n",
    "                    -1, act.shape[-1]\n",
    "                )  # Reshape to [batch*spatial, d_model]\n",
    "\n",
    "                # Get latent activations using model2 encoder\n",
    "                latents = einops.einsum(\n",
    "                    act,\n",
    "                    crosscoder.W_enc[1],  # Use model2 encoder weights\n",
    "                    \"batch d_model, d_model d_latent -> batch d_latent\",\n",
    "                )\n",
    "                latents = torch.nn.functional.relu(\n",
    "                    latents + crosscoder.b_enc[1]\n",
    "                )  # Use model2 bias\n",
    "\n",
    "                # Count activated neurons at each spatial position\n",
    "                activated_per_position = (latents > threshold).float().cpu()\n",
    "\n",
    "                # Count across all spatial positions for each neuron type\n",
    "                base_activated = (\n",
    "                    activated_per_position[:, only_base_features_mask].sum(dim=1).mean()\n",
    "                ).item()\n",
    "                shared_activated = (\n",
    "                    activated_per_position[:, shared_features_mask].sum(dim=1).mean()\n",
    "                ).item()\n",
    "                distilled_activated = (\n",
    "                    activated_per_position[:, only_turbo_features_mask]\n",
    "                    .sum(dim=1)\n",
    "                    .mean()\n",
    "                ).item()\n",
    "\n",
    "                # Add to counts\n",
    "                model2_activated_counts[ts][\"base\"] += base_activated\n",
    "                model2_activated_counts[ts][\"shared\"] += shared_activated\n",
    "                model2_activated_counts[ts][\"distilled\"] += distilled_activated\n",
    "                model2_activated_counts[ts][\"samples\"] += 1\n",
    "\n",
    "    return {\"model1\": model1_activated_counts, \"model2\": model2_activated_counts}\n",
    "\n",
    "\n",
    "# Run the function to collect data\n",
    "activated_neurons_data_both_models = plot_activated_neurons_by_group_both_models(\n",
    "    threshold=0.01\n",
    ")\n",
    "\n",
    "# Create a combined plot outside the function\n",
    "# Extract data for plotting\n",
    "model1_data = activated_neurons_data_both_models[\"model1\"]\n",
    "model2_data = activated_neurons_data_both_models[\"model2\"]\n",
    "\n",
    "# Find common timesteps between both models\n",
    "common_timesteps = sorted(set(model1_data.keys()).intersection(set(model2_data.keys())))\n",
    "\n",
    "# Calculate averages for each model and timestep\n",
    "model1_timesteps = []\n",
    "model1_base_counts = []\n",
    "model1_shared_counts = []\n",
    "model1_distilled_counts = []\n",
    "\n",
    "model2_timesteps = []\n",
    "model2_base_counts = []\n",
    "model2_shared_counts = []\n",
    "model2_distilled_counts = []\n",
    "\n",
    "for ts in common_timesteps:\n",
    "    if model1_data[ts][\"samples\"] > 0 and model2_data[ts][\"samples\"] > 0:\n",
    "        # Add to model1 data\n",
    "        model1_timesteps.append(ts)\n",
    "        model1_base_counts.append(model1_data[ts][\"base\"] / model1_data[ts][\"samples\"])\n",
    "        model1_shared_counts.append(\n",
    "            model1_data[ts][\"shared\"] / model1_data[ts][\"samples\"]\n",
    "        )\n",
    "        model1_distilled_counts.append(\n",
    "            model1_data[ts][\"distilled\"] / model1_data[ts][\"samples\"]\n",
    "        )\n",
    "\n",
    "        # Add to model2 data\n",
    "        model2_timesteps.append(ts)\n",
    "        model2_base_counts.append(model2_data[ts][\"base\"] / model2_data[ts][\"samples\"])\n",
    "        model2_shared_counts.append(\n",
    "            model2_data[ts][\"shared\"] / model2_data[ts][\"samples\"]\n",
    "        )\n",
    "        model2_distilled_counts.append(\n",
    "            model2_data[ts][\"distilled\"] / model2_data[ts][\"samples\"]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined plot outside the function\n",
    "# Extract data for plotting\n",
    "model1_data = activated_neurons_data_both_models[\"model1\"]\n",
    "model2_data = activated_neurons_data_both_models[\"model2\"]\n",
    "\n",
    "# Find common timesteps between both models and filter to desired range (999 to 249)\n",
    "common_timesteps = sorted(\n",
    "    [\n",
    "        ts\n",
    "        for ts in set(model1_data.keys()).intersection(set(model2_data.keys()))\n",
    "        if 249 <= ts <= 999\n",
    "    ],\n",
    "    reverse=True,  # Sort in descending order (from 999 to 249)\n",
    ")\n",
    "\n",
    "# Calculate averages for each model and timestep\n",
    "model1_timesteps = []\n",
    "model1_base_counts = []\n",
    "model1_shared_counts = []\n",
    "model1_distilled_counts = []\n",
    "\n",
    "model2_timesteps = []\n",
    "model2_base_counts = []\n",
    "model2_shared_counts = []\n",
    "model2_distilled_counts = []\n",
    "\n",
    "for ts in common_timesteps:\n",
    "    if model1_data[ts][\"samples\"] > 0 and model2_data[ts][\"samples\"] > 0:\n",
    "        # Add to model1 data\n",
    "        model1_timesteps.append(ts)\n",
    "        model1_base_counts.append(model1_data[ts][\"base\"] / model1_data[ts][\"samples\"])\n",
    "        model1_shared_counts.append(\n",
    "            model1_data[ts][\"shared\"] / model1_data[ts][\"samples\"]\n",
    "        )\n",
    "        model1_distilled_counts.append(\n",
    "            model1_data[ts][\"distilled\"] / model1_data[ts][\"samples\"]\n",
    "        )\n",
    "\n",
    "        # Add to model2 data\n",
    "        model2_timesteps.append(ts)\n",
    "        model2_base_counts.append(model2_data[ts][\"base\"] / model2_data[ts][\"samples\"])\n",
    "        model2_shared_counts.append(\n",
    "            model2_data[ts][\"shared\"] / model2_data[ts][\"samples\"]\n",
    "        )\n",
    "        model2_distilled_counts.append(\n",
    "            model2_data[ts][\"distilled\"] / model2_data[ts][\"samples\"]\n",
    "        )\n",
    "\n",
    "# Create plot with grouped bars for each timestep\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.ylim(0, 60)\n",
    "# Set positions for grouped bars\n",
    "bar_width = 0.35\n",
    "x_positions = np.arange(len(common_timesteps))\n",
    "\n",
    "# Plot model1 (Base model) bars with hatching\n",
    "plt.bar(\n",
    "    x_positions - bar_width / 2,\n",
    "    model1_base_counts,\n",
    "    bar_width,\n",
    "    color=colors[1],\n",
    "    hatch=\"//\",\n",
    "    edgecolor=\"black\",\n",
    "    alpha=0.4,\n",
    ")\n",
    "plt.bar(\n",
    "    x_positions - bar_width / 2,\n",
    "    model1_shared_counts,\n",
    "    bar_width,\n",
    "    bottom=model1_base_counts,\n",
    "    color=colors[2],\n",
    "    hatch=\"//\",\n",
    "    edgecolor=\"black\",\n",
    "    alpha=0.4,\n",
    ")\n",
    "# Calculate bottoms for the third bar segment\n",
    "model1_bottoms = [b + s for b, s in zip(model1_base_counts, model1_shared_counts)]\n",
    "plt.bar(\n",
    "    x_positions - bar_width / 2,\n",
    "    model1_distilled_counts,\n",
    "    bar_width,\n",
    "    bottom=model1_bottoms,\n",
    "    color=colors[-2],\n",
    "    hatch=\"//\",\n",
    "    edgecolor=\"black\",\n",
    "    alpha=0.4,\n",
    ")\n",
    "\n",
    "# Plot model2 (Distilled model) bars\n",
    "plt.bar(\n",
    "    x_positions + bar_width / 2,\n",
    "    model2_base_counts,\n",
    "    bar_width,\n",
    "    color=colors[1],\n",
    "    alpha=0.4,\n",
    ")\n",
    "plt.bar(\n",
    "    x_positions + bar_width / 2,\n",
    "    model2_shared_counts,\n",
    "    bar_width,\n",
    "    bottom=model2_base_counts,\n",
    "    color=colors[2],\n",
    "    alpha=0.4,\n",
    ")\n",
    "# Calculate bottoms for the third bar segment\n",
    "model2_bottoms = [b + s for b, s in zip(model2_base_counts, model2_shared_counts)]\n",
    "plt.bar(\n",
    "    x_positions + bar_width / 2,\n",
    "    model2_distilled_counts,\n",
    "    bar_width,\n",
    "    bottom=model2_bottoms,\n",
    "    color=colors[-2],\n",
    "    alpha=0.4,\n",
    ")\n",
    "\n",
    "# Add model labels above each bar\n",
    "for i in range(len(x_positions)):\n",
    "    # Calculate the total height for each model's bar\n",
    "    model1_total = (\n",
    "        model1_base_counts[i] + model1_shared_counts[i] + model1_distilled_counts[i]\n",
    "    )\n",
    "    model2_total = (\n",
    "        model2_base_counts[i] + model2_shared_counts[i] + model2_distilled_counts[i]\n",
    "    )\n",
    "\n",
    "    # Add a small offset to position the text right above each bar\n",
    "    offset = 0.8\n",
    "\n",
    "    plt.text(\n",
    "        x_positions[i] - bar_width / 2,\n",
    "        model1_total + offset,\n",
    "        \"Base\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=SMALL_SIZE,\n",
    "    )\n",
    "\n",
    "    plt.text(\n",
    "        x_positions[i] + bar_width / 2,\n",
    "        model2_total + offset,\n",
    "        \"Distilled\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=SMALL_SIZE,\n",
    "    )\n",
    "\n",
    "# Set chart labels and properties\n",
    "plt.ylabel(\"Average L0 (Active Neurons)\")\n",
    "plt.title(\"Average Number of Activated Neurons from each Feature Group\")\n",
    "plt.xticks(x_positions, [f\"Timestep {int(ts)}\" for ts in common_timesteps])\n",
    "\n",
    "# Create a simplified legend with only the feature types\n",
    "custom_handles = [\n",
    "    plt.Rectangle((0, 0), 1, 1, color=colors[1], alpha=0.4),\n",
    "    plt.Rectangle((0, 0), 1, 1, color=colors[2], alpha=0.4),\n",
    "    plt.Rectangle((0, 0), 1, 1, color=colors[-2], alpha=0.4),\n",
    "]\n",
    "custom_labels = [\"Base-specific\", \"Shared\", \"Distilled-specific\"]\n",
    "plt.legend(custom_handles, custom_labels, loc=\"upper left\")\n",
    "\n",
    "plt.grid(axis=\"y\", alpha=0.25, linestyle=\"--\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    \"figures/activated_neurons_both_models_combined.pdf\",\n",
    "    dpi=300,\n",
    "    format=\"pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find neurons that activate most frequently on timestep 999\n",
    "def find_most_active_neurons_for_timestep(target_timestep=999, top_k=30, threshold=0.0):\n",
    "    print(f\"Finding neurons most active on timestep {target_timestep}...\")\n",
    "\n",
    "    # Get the index for this timestep in our timestep_map\n",
    "    timestep_idx = None\n",
    "    for i, ts in enumerate(timestep_map):\n",
    "        if ts == target_timestep:\n",
    "            timestep_idx = i\n",
    "            break\n",
    "\n",
    "    if timestep_idx is None:\n",
    "        raise ValueError(f\"Timestep {target_timestep} not found in timestep_map\")\n",
    "\n",
    "    # Initialize counters for neuron activation\n",
    "    neuron_activation_count = torch.zeros(crosscoder.num_latents, device=\"cpu\")\n",
    "    total_samples = 0\n",
    "\n",
    "    # Process dataset in batches\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dl, desc=f\"Processing timestep {target_timestep}\"):\n",
    "            acts = batch[\"activations\"]\n",
    "            timesteps = batch[\"timestep\"]\n",
    "\n",
    "            # Only process samples for our target timestep\n",
    "            mask = timesteps == target_timestep\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            timestep_acts = acts[mask]\n",
    "\n",
    "            # Process activations\n",
    "            timestep_acts = timestep_acts.to(crosscoder.W_dec.device)\n",
    "            batch_size = timestep_acts.shape[0]\n",
    "\n",
    "            # Reshape and normalize\n",
    "            timestep_acts = einops.rearrange(\n",
    "                timestep_acts,\n",
    "                \"batch sample_size d_model -> (batch sample_size) d_model\",\n",
    "            )\n",
    "            timestep_acts = (\n",
    "                timestep_acts * paired_dataset.norm_scaling_factors[0]\n",
    "            )  # Model 2\n",
    "\n",
    "            # Forward through encoder to get latent activations\n",
    "            latents = einops.einsum(\n",
    "                timestep_acts,\n",
    "                crosscoder.W_enc[0],  # Model 2\n",
    "                \"batch d_model, d_model d_latent -> batch d_latent\",\n",
    "            )\n",
    "            latents = torch.nn.functional.relu(latents + crosscoder.b_enc[0])\n",
    "\n",
    "            # Count activated neurons (activation > threshold)\n",
    "            activated = (latents > threshold).float()\n",
    "            neuron_activation_count += activated.sum(dim=0).cpu()\n",
    "            total_samples += latents.shape[0]\n",
    "\n",
    "    # Calculate activation frequency (percentage of samples where neuron activated)\n",
    "    if total_samples > 0:\n",
    "        activation_frequency = neuron_activation_count / total_samples\n",
    "    else:\n",
    "        print(f\"Warning: No samples found for timestep {target_timestep}\")\n",
    "        return None, None\n",
    "\n",
    "    # Get top-k most frequently activated neurons\n",
    "    top_values, top_indices = torch.topk(activation_frequency, top_k)\n",
    "\n",
    "    # Determine neuron types\n",
    "    neuron_types = []\n",
    "    for idx in top_indices:\n",
    "        if only_base_features_mask[idx]:\n",
    "            neuron_types.append(\"Base\")\n",
    "        elif only_turbo_features_mask[idx]:\n",
    "            neuron_types.append(\"Turbo\")\n",
    "        elif shared_features_mask[idx]:\n",
    "            neuron_types.append(\"Shared\")\n",
    "        else:\n",
    "            neuron_types.append(\"Unknown\")\n",
    "\n",
    "    return top_indices, top_values, neuron_types\n",
    "\n",
    "\n",
    "# Find top 30 most active neurons for timestep 999\n",
    "top_indices, top_frequencies, neuron_types = find_most_active_neurons_for_timestep(\n",
    "    target_timestep=999, top_k=50, threshold=0.0\n",
    ")\n",
    "\n",
    "# Display results\n",
    "if top_indices is not None:\n",
    "    # Create a table with results\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    table_data = []\n",
    "    for i in range(len(top_indices)):\n",
    "        neuron_idx = top_indices[i].item()\n",
    "        freq = top_frequencies[i].item()\n",
    "        neuron_type = neuron_types[i]\n",
    "        table_data.append(\n",
    "            [neuron_idx, f\"{freq:.4f}\", f\"{freq * 100:.2f}%\", neuron_type]\n",
    "        )\n",
    "\n",
    "    # Create table\n",
    "    plt.axis(\"off\")\n",
    "    table = plt.table(\n",
    "        cellText=table_data,\n",
    "        colLabels=[\"Neuron Index\", \"Activation Frequency\", \"Percentage\", \"Type\"],\n",
    "        loc=\"center\",\n",
    "        cellLoc=\"center\",\n",
    "    )\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.5)\n",
    "\n",
    "    plt.title(\n",
    "        f\"Top {len(top_indices)} Neurons Most Frequently Active at Timestep 999\",\n",
    "        fontsize=16,\n",
    "        pad=20,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Also create a bar chart\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    bars = plt.bar(range(len(top_indices)), top_frequencies.numpy() * 100)\n",
    "\n",
    "    # Color bars by neuron type\n",
    "    for i, bar in enumerate(bars):\n",
    "        if neuron_types[i] == \"Base\":\n",
    "            bar.set_color(colors[0])\n",
    "        elif neuron_types[i] == \"Turbo\":\n",
    "            bar.set_color(colors[2])\n",
    "        elif neuron_types[i] == \"Shared\":\n",
    "            bar.set_color(colors[1])\n",
    "\n",
    "    # Add neuron indices as x-tick labels\n",
    "    plt.xticks(\n",
    "        range(len(top_indices)), [f\"{idx.item()}\" for idx in top_indices], rotation=45\n",
    "    )\n",
    "\n",
    "    # Add neuron type annotations above each bar\n",
    "    for i, bar in enumerate(bars):\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height() + 1,\n",
    "            neuron_types[i],\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            rotation=90,\n",
    "            fontsize=8,\n",
    "        )\n",
    "\n",
    "    plt.title(\"Top Neurons by Activation Frequency at Timestep 999\", fontsize=16)\n",
    "    plt.xlabel(\"Neuron Index\", fontsize=14)\n",
    "    plt.ylabel(\"Activation Frequency (%)\", fontsize=14)\n",
    "    plt.grid(axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Create a pie chart showing the distribution of neuron types in the top active neurons\n",
    "    type_counts = {\"Base\": 0, \"Turbo\": 0, \"Shared\": 0}\n",
    "    for t in neuron_types:\n",
    "        type_counts[t] += 1\n",
    "\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.pie(\n",
    "        list(type_counts.values()),\n",
    "        labels=list(type_counts.keys()),\n",
    "        autopct=\"%1.1f%%\",\n",
    "        startangle=90,\n",
    "        colors=[colors[0], colors[2], colors[1]],\n",
    "    )\n",
    "    plt.title(\n",
    "        f\"Distribution of Neuron Types Among Top {len(top_indices)} Active at Timestep 999\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find neurons that activate most frequently on a specific timestep for both models\n",
    "def compare_most_active_neurons(target_timestep=999, top_k=20, threshold=0.0):\n",
    "    print(f\"Finding neurons most active on timestep {target_timestep}...\")\n",
    "\n",
    "    # Get the index for this timestep in our timestep_map\n",
    "    timestep_idx = None\n",
    "    for i, ts in enumerate(timestep_map):\n",
    "        if ts == target_timestep:\n",
    "            timestep_idx = i\n",
    "            break\n",
    "\n",
    "    if timestep_idx is None:\n",
    "        raise ValueError(f\"Timestep {target_timestep} not found in timestep_map\")\n",
    "\n",
    "    # Initialize counters for neuron activation - base model\n",
    "    base_neuron_activation_count = torch.zeros(crosscoder.num_latents, device=\"cpu\")\n",
    "    base_total_samples = 0\n",
    "\n",
    "    # Initialize counters for neuron activation - distilled model\n",
    "    distilled_neuron_activation_count = torch.zeros(\n",
    "        crosscoder.num_latents, device=\"cpu\"\n",
    "    )\n",
    "    distilled_total_samples = 0\n",
    "\n",
    "    # Process base model dataset\n",
    "    base_dl = torch.utils.data.DataLoader(\n",
    "        model1_dataset, batch_size=16, shuffle=False, num_workers=4\n",
    "    )\n",
    "    distilled_dl = torch.utils.data.DataLoader(\n",
    "        model2_dataset, batch_size=16, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "    # Process base model dataset\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(\n",
    "            base_dl, desc=f\"Processing base model - timestep {target_timestep}\"\n",
    "        ):\n",
    "            acts = batch[\"activations\"]\n",
    "            timesteps = batch[\"timestep\"]\n",
    "\n",
    "            # Only process samples for our target timestep\n",
    "            mask = timesteps == target_timestep\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            timestep_acts = acts[mask]\n",
    "\n",
    "            # Process activations\n",
    "            timestep_acts = timestep_acts.to(crosscoder.W_dec.device)\n",
    "            batch_size = timestep_acts.shape[0]\n",
    "\n",
    "            # Reshape and normalize\n",
    "            timestep_acts = einops.rearrange(\n",
    "                timestep_acts,\n",
    "                \"batch sample_size d_model -> (batch sample_size) d_model\",\n",
    "            )\n",
    "            timestep_acts = timestep_acts * paired_dataset.norm_scaling_factors[0]\n",
    "\n",
    "            # Forward through encoder to get latent activations\n",
    "            latents = einops.einsum(\n",
    "                timestep_acts,\n",
    "                crosscoder.W_enc[0],\n",
    "                \"batch d_model, d_model d_latent -> batch d_latent\",\n",
    "            )\n",
    "            latents = torch.nn.functional.relu(latents + crosscoder.b_enc[0])\n",
    "\n",
    "            # Count activated neurons (activation > threshold)\n",
    "            activated = (latents > threshold).float()\n",
    "            base_neuron_activation_count += activated.sum(dim=0).cpu()\n",
    "            base_total_samples += latents.shape[0]\n",
    "\n",
    "    # Process distilled model dataset\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(\n",
    "            distilled_dl,\n",
    "            desc=f\"Processing distilled model - timestep {target_timestep}\",\n",
    "        ):\n",
    "            acts = batch[\"activations\"]\n",
    "            timesteps = batch[\"timestep\"]\n",
    "\n",
    "            # Only process samples for our target timestep\n",
    "            mask = timesteps == target_timestep\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            timestep_acts = acts[mask]\n",
    "\n",
    "            # Process activations\n",
    "            timestep_acts = timestep_acts.to(crosscoder.W_dec.device)\n",
    "            batch_size = timestep_acts.shape[0]\n",
    "\n",
    "            # Reshape and normalize\n",
    "            timestep_acts = einops.rearrange(\n",
    "                timestep_acts,\n",
    "                \"batch sample_size d_model -> (batch sample_size) d_model\",\n",
    "            )\n",
    "            timestep_acts = timestep_acts * paired_dataset.norm_scaling_factors[1]\n",
    "\n",
    "            # Forward through encoder to get latent activations\n",
    "            latents = einops.einsum(\n",
    "                timestep_acts,\n",
    "                crosscoder.W_enc[1],\n",
    "                \"batch d_model, d_model d_latent -> batch d_latent\",\n",
    "            )\n",
    "            latents = torch.nn.functional.relu(latents + crosscoder.b_enc[1])\n",
    "\n",
    "            # Count activated neurons (activation > threshold)\n",
    "            activated = (latents > threshold).float()\n",
    "            distilled_neuron_activation_count += activated.sum(dim=0).cpu()\n",
    "            distilled_total_samples += latents.shape[0]\n",
    "\n",
    "    # Calculate activation frequency for base model\n",
    "    if base_total_samples > 0:\n",
    "        base_activation_frequency = base_neuron_activation_count / base_total_samples\n",
    "    else:\n",
    "        print(f\"Warning: No base model samples found for timestep {target_timestep}\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Calculate activation frequency for distilled model\n",
    "    if distilled_total_samples > 0:\n",
    "        distilled_activation_frequency = (\n",
    "            distilled_neuron_activation_count / distilled_total_samples\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            f\"Warning: No distilled model samples found for timestep {target_timestep}\"\n",
    "        )\n",
    "        return None, None, None\n",
    "\n",
    "    # Get top-k most frequently activated neurons in the base model\n",
    "    top_values, top_indices = torch.topk(base_activation_frequency, top_k)\n",
    "\n",
    "    # Get activation frequencies for those same neurons in the distilled model\n",
    "    distilled_values = distilled_activation_frequency[top_indices]\n",
    "\n",
    "    # Determine neuron types\n",
    "    neuron_types = []\n",
    "    for idx in top_indices:\n",
    "        if only_base_features_mask[idx]:\n",
    "            neuron_types.append(\"Base\")\n",
    "        elif only_turbo_features_mask[idx]:\n",
    "            neuron_types.append(\"Distilled\")\n",
    "        elif shared_features_mask[idx]:\n",
    "            neuron_types.append(\"Shared\")\n",
    "        else:\n",
    "            neuron_types.append(\"Unknown\")\n",
    "\n",
    "    return top_indices, top_values, distilled_values, neuron_types\n",
    "\n",
    "\n",
    "# Find top 20 most active neurons for timestep 999 in both models\n",
    "top_indices, base_frequencies, distilled_frequencies, neuron_types = (\n",
    "    compare_most_active_neurons(target_timestep=999, top_k=20, threshold=0.0)\n",
    ")\n",
    "\n",
    "# Create the comparison bar plot\n",
    "if top_indices is not None:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Set positions for the bars\n",
    "    bar_width = 0.35\n",
    "    x_positions = np.arange(len(top_indices))\n",
    "\n",
    "    # Create grouped bars for both models\n",
    "    bars1 = plt.bar(\n",
    "        x_positions - bar_width / 2,\n",
    "        base_frequencies.numpy() * 100,\n",
    "        bar_width,\n",
    "        label=\"Base Model\",\n",
    "        color=colors[0],\n",
    "    )\n",
    "\n",
    "    bars2 = plt.bar(\n",
    "        x_positions + bar_width / 2,\n",
    "        distilled_frequencies.numpy() * 100,\n",
    "        bar_width,\n",
    "        label=\"Distilled Model\",\n",
    "        color=colors[2],\n",
    "    )\n",
    "\n",
    "    # Set plot aesthetics\n",
    "    plt.xlabel(\"Neuron Index\")\n",
    "    plt.ylabel(\"Activation Frequency (%)\")\n",
    "    plt.title(\n",
    "        f\"Activation Comparison of Top {len(top_indices)} Most Active Neurons at Timestep 999\"\n",
    "    )\n",
    "    plt.xticks(x_positions, [f\"{idx.item()}\" for idx in top_indices], rotation=45)\n",
    "\n",
    "    # Add neuron type markers at the top of the plot\n",
    "    for i, neuron_type in enumerate(neuron_types):\n",
    "        plt.text(\n",
    "            x_positions[i],\n",
    "            max(base_frequencies[i], distilled_frequencies[i]) * 100 + 2,\n",
    "            neuron_type,\n",
    "            ha=\"center\",\n",
    "            rotation=45,\n",
    "            fontsize=9,\n",
    "            color=\"black\",\n",
    "        )\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(\n",
    "        \"figures/neuron_activation_comparison.pdf\",\n",
    "        dpi=300,\n",
    "        format=\"pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    crosscoder.W_dec.shape,\n",
    "    crosscoder.W_enc.shape,\n",
    "    crosscoder.b_dec.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze activations for a single sample\n",
    "def analyze_sample_activations(sample_idx=0, threshold=0.1, top_k=20):\n",
    "    \"\"\"\n",
    "    Analyze and display neurons activated in both models for a single sample\n",
    "\n",
    "    Args:\n",
    "        sample_idx: Index of the sample in the paired dataset\n",
    "        threshold: Activation threshold to consider a neuron as \"active\"\n",
    "        top_k: Number of top activated neurons to display\n",
    "    \"\"\"\n",
    "    # Get the sample from paired dataset\n",
    "    sample = paired_dataset[sample_idx]\n",
    "\n",
    "    # Extract activations for both models\n",
    "    acts_model1 = sample[\"model1\"].to(crosscoder.W_dec.device)  # Base model\n",
    "    acts_model2 = sample[\"model2\"].to(crosscoder.W_dec.device)  # Distilled model\n",
    "    timestep1 = sample[\"model1_timestep\"].item()\n",
    "    timestep2 = sample[\"model2_timestep\"].item()\n",
    "\n",
    "    # Get latent activations for each model\n",
    "    # Base model\n",
    "    latents_model1 = einops.einsum(\n",
    "        acts_model1,\n",
    "        crosscoder.W_enc[0],\n",
    "        \"sample_size d_model, d_model d_latent -> sample_size d_latent\",\n",
    "    )\n",
    "    latents_model1 = torch.nn.functional.relu(latents_model1 + crosscoder.b_enc[0])\n",
    "\n",
    "    # Distilled model\n",
    "    latents_model2 = einops.einsum(\n",
    "        acts_model2,\n",
    "        crosscoder.W_enc[1],\n",
    "        \"sample_size d_model, d_model d_latent -> sample_size d_latent\",\n",
    "    )\n",
    "    latents_model2 = torch.nn.functional.relu(latents_model2 + crosscoder.b_enc[1])\n",
    "\n",
    "    # Calculate mean activations across spatial positions\n",
    "    avg_latents_model1 = latents_model1.mean(dim=0)\n",
    "    avg_latents_model2 = latents_model2.mean(dim=0)\n",
    "\n",
    "    # Identify active neurons in each model\n",
    "    active_neurons_model1 = (avg_latents_model1 > threshold).cpu()\n",
    "    active_neurons_model2 = (avg_latents_model2 > threshold).cpu()\n",
    "\n",
    "    # Find neurons active in both models\n",
    "    active_in_both = active_neurons_model1 & active_neurons_model2\n",
    "\n",
    "    # Count active neurons\n",
    "    num_active_model1 = active_neurons_model1.sum().item()\n",
    "    num_active_model2 = active_neurons_model2.sum().item()\n",
    "    num_active_both = active_in_both.sum().item()\n",
    "\n",
    "    # Check for which feature types the neurons belong to\n",
    "    active_base_specific = active_neurons_model1 & only_base_features_mask\n",
    "    active_distilled_specific = active_neurons_model2 & only_turbo_features_mask\n",
    "    active_shared = active_in_both & shared_features_mask\n",
    "\n",
    "    # Print statistics\n",
    "    print(f\"Sample Index: {sample_idx}, File: {sample['file_name']}\")\n",
    "    print(f\"Timesteps: Base = {int(timestep1)}, Distilled = {int(timestep2)}\")\n",
    "    print(f\"Active neurons in Base model: {num_active_model1}\")\n",
    "    print(f\"Active neurons in Distilled model: {num_active_model2}\")\n",
    "    print(f\"Neurons active in both models: {num_active_both}\")\n",
    "    print(f\"  - Base-specific neurons active: {active_base_specific.sum().item()}\")\n",
    "    print(\n",
    "        f\"  - Distilled-specific neurons active: {active_distilled_specific.sum().item()}\"\n",
    "    )\n",
    "    print(f\"  - Shared neurons active: {active_shared.sum().item()}\")\n",
    "\n",
    "    # Find top-k activating neurons for each model\n",
    "    top_neurons_model1 = torch.topk(avg_latents_model1, top_k)\n",
    "    top_neurons_model2 = torch.topk(avg_latents_model2, top_k)\n",
    "\n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Display image\n",
    "    img = Image.open(os.path.join(dataset_path, sample[\"file_name\"]))\n",
    "    img = img.resize((512, 512))\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title(f\"Sample Image\\n{os.path.basename(sample['file_name'])}\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    # Create a visualization of neuron types\n",
    "    neuron_types = np.zeros(crosscoder.num_latents)\n",
    "    # 1 for base-only, 2 for distilled-only, 3 for shared\n",
    "    neuron_types[only_base_features_mask.cpu().numpy()] = 1\n",
    "    neuron_types[only_turbo_features_mask.cpu().numpy()] = 2\n",
    "    neuron_types[shared_features_mask.cpu().numpy()] = 3\n",
    "\n",
    "    # Create a visualization of active neurons\n",
    "    active_status = np.zeros(crosscoder.num_latents)\n",
    "    active_status[active_neurons_model1.cpu().numpy()] = 1\n",
    "    active_status[active_neurons_model2.cpu().numpy()] += 2\n",
    "    # Now: 0=inactive, 1=base-only, 2=distilled-only, 3=both\n",
    "\n",
    "    # Plot the top activating neurons\n",
    "    bar_width = 0.35\n",
    "    x_positions = np.arange(top_k)\n",
    "\n",
    "    axes[1].bar(\n",
    "        x_positions - bar_width / 2,\n",
    "        top_neurons_model1.values.cpu().numpy(),\n",
    "        bar_width,\n",
    "        label=\"Base Model\",\n",
    "        color=colors[0],\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "    axes[1].bar(\n",
    "        x_positions + bar_width / 2,\n",
    "        top_neurons_model2.values.cpu().numpy(),\n",
    "        bar_width,\n",
    "        label=\"Distilled Model\",\n",
    "        color=colors[2],\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "    # Annotate with neuron indices and types\n",
    "    for i in range(top_k):\n",
    "        idx1 = top_neurons_model1.indices[i].item()\n",
    "        idx2 = top_neurons_model2.indices[i].item()\n",
    "\n",
    "        # Add annotations\n",
    "        axes[1].text(\n",
    "            x_positions[i] - bar_width / 2,\n",
    "            top_neurons_model1.values[i].item() + 0.01,\n",
    "            f\"{idx1}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            rotation=45,\n",
    "        )\n",
    "\n",
    "        axes[1].text(\n",
    "            x_positions[i] + bar_width / 2,\n",
    "            top_neurons_model2.values[i].item() + 0.01,\n",
    "            f\"{idx2}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            rotation=45,\n",
    "        )\n",
    "\n",
    "    axes[1].set_xticks(x_positions)\n",
    "    axes[1].set_xticklabels([f\"{i + 1}\" for i in range(top_k)])\n",
    "    axes[1].set_xlabel(\"Rank\")\n",
    "    axes[1].set_ylabel(\"Activation Value\")\n",
    "    axes[1].set_title(\"Top Activating Neurons\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return latents_model1, latents_model2\n",
    "\n",
    "\n",
    "# Call the function with sample index 0\n",
    "latents1, latents2 = analyze_sample_activations(sample_idx=6, threshold=0.0, top_k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_top_activations(sample_idx, dataset_path, threshold=0.01, top_k=5):\n",
    "    \"\"\"\n",
    "    Visualize top activating neurons for both models on a specific sample.\n",
    "\n",
    "    Args:\n",
    "        sample_idx: Index of the sample to visualize\n",
    "        dataset_path: Path to the dataset containing images\n",
    "        threshold: Activation threshold\n",
    "        top_k: Number of top neurons to display\n",
    "    \"\"\"\n",
    "    # Get the sample\n",
    "    sample = paired_dataset[sample_idx]\n",
    "\n",
    "    # Get activations for both models\n",
    "    model1_act = sample[\"model1\"].unsqueeze(0).to(crosscoder.W_dec.device)  # Base model\n",
    "    model2_act = (\n",
    "        sample[\"model2\"].unsqueeze(0).to(crosscoder.W_dec.device)\n",
    "    )  # Distilled model\n",
    "\n",
    "    # Get timesteps\n",
    "    model1_ts = sample[\"model1_timestep\"].item()\n",
    "    model2_ts = sample[\"model2_timestep\"].item()\n",
    "\n",
    "    # Load the original image\n",
    "    img_path = os.path.join(dataset_path, sample[\"file_name\"])\n",
    "    original_img = Image.open(img_path)\n",
    "    original_img = original_img.resize((512, 512))  # Resize to consistent dimensions\n",
    "    original_img = original_img.convert(\"RGB\")  # Ensure RGB format\n",
    "\n",
    "    # Process through encoders\n",
    "    with torch.no_grad():\n",
    "        # Base model\n",
    "        model1_act_reshaped = model1_act.reshape(-1, model1_act.shape[-1])\n",
    "        model1_latents = einops.einsum(\n",
    "            model1_act_reshaped,\n",
    "            crosscoder.W_enc[0],\n",
    "            \"batch d_model, d_model d_latent -> batch d_latent\",\n",
    "        )\n",
    "        model1_latents = torch.nn.functional.relu(model1_latents + crosscoder.b_enc[0])\n",
    "\n",
    "        # Distilled model\n",
    "        model2_act_reshaped = model2_act.reshape(-1, model2_act.shape[-1])\n",
    "        model2_latents = einops.einsum(\n",
    "            model2_act_reshaped,\n",
    "            crosscoder.W_enc[1],  # Use model2 encoder weights\n",
    "            \"batch d_model, d_model d_latent -> batch d_latent\",\n",
    "        )\n",
    "        model2_latents = torch.nn.functional.relu(model2_latents + crosscoder.b_enc[1])\n",
    "\n",
    "    # Get average activation per neuron across spatial positions\n",
    "    model1_avg_activations = model1_latents.mean(dim=0)\n",
    "    model2_avg_activations = model2_latents.mean(dim=0)\n",
    "\n",
    "    # Get neurons that exceed the threshold\n",
    "    model1_active_neurons = (\n",
    "        (model1_avg_activations > threshold).nonzero().squeeze().cpu().numpy()\n",
    "    )\n",
    "    model2_active_neurons = (\n",
    "        (model2_avg_activations > threshold).nonzero().squeeze().cpu().numpy()\n",
    "    )\n",
    "\n",
    "    # Get the top_k neurons with highest activations\n",
    "    model1_top_neurons = (\n",
    "        torch.argsort(model1_avg_activations, descending=True)[:top_k].cpu().numpy()\n",
    "    )\n",
    "    model2_top_neurons = (\n",
    "        torch.argsort(model2_avg_activations, descending=True)[:top_k].cpu().numpy()\n",
    "    )\n",
    "\n",
    "    # Create a figure with 2 rows, top_k columns\n",
    "    fig, axes = plt.subplots(2, top_k, figsize=(top_k * 3, 6))\n",
    "\n",
    "    # # Add title\n",
    "    # fig.suptitle(\n",
    "    #     f\"Top {top_k} Activated Neurons for Sample {sample_idx}\",\n",
    "    # )\n",
    "\n",
    "    # Function to overlay activations on image using the original method\n",
    "    def plot_activation_overlay(ax, neuron_idx, model_idx, latents, activation_value):\n",
    "        # Make a copy of the original image for this subplot\n",
    "        img = original_img.copy()\n",
    "\n",
    "        # Get spatial activations for this neuron\n",
    "        spatial_dim = int(np.sqrt(latents.shape[0]))\n",
    "        spatial_activations = (\n",
    "            latents[:, neuron_idx]\n",
    "            .reshape(spatial_dim, spatial_dim)\n",
    "            .detach()\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "\n",
    "        # Normalize for visualization\n",
    "        activation_map = (spatial_activations - spatial_activations.min()) / (\n",
    "            spatial_activations.max() - spatial_activations.min() + 1e-8\n",
    "        )\n",
    "\n",
    "        # Calculate upscale factor to match image size\n",
    "        patch_size = 512 // activation_map.shape[0]\n",
    "        activation_map = np.kron(activation_map, np.ones((patch_size, patch_size)))\n",
    "\n",
    "        # Create heatmap overlay using jet colormap\n",
    "        heatmap = np.uint8(plt.cm.jet(activation_map)[..., :3] * 255)\n",
    "        heatmap = Image.fromarray(heatmap)\n",
    "\n",
    "        # Blend original image with heatmap\n",
    "        blended_img = Image.blend(img, heatmap, alpha=0.4)\n",
    "\n",
    "        # Display the blended image\n",
    "        ax.imshow(np.array(blended_img))\n",
    "\n",
    "        # Remove ticks\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        # For base model (top row), add neuron ID above\n",
    "        if model_idx == 0:\n",
    "            ax.set_title(f\"#{neuron_idx}\")\n",
    "        # For distilled model (bottom row), add neuron ID below\n",
    "        else:\n",
    "            ax.set_xlabel(f\"#{neuron_idx}\")\n",
    "\n",
    "    # Plot base model activations (top row)\n",
    "    for i in range(top_k):\n",
    "        neuron_idx = model1_top_neurons[i]\n",
    "        activation_value = model1_avg_activations[neuron_idx].item()\n",
    "        plot_activation_overlay(\n",
    "            axes[0, i], neuron_idx, 0, model1_latents, activation_value\n",
    "        )\n",
    "\n",
    "    # Plot distilled model activations (bottom row)\n",
    "    for i in range(top_k):\n",
    "        neuron_idx = model2_top_neurons[i]\n",
    "        activation_value = model2_avg_activations[neuron_idx].item()\n",
    "        plot_activation_overlay(\n",
    "            axes[1, i], neuron_idx, 1, model2_latents, activation_value\n",
    "        )\n",
    "\n",
    "    # Add row labels\n",
    "    axes[0, 0].set_ylabel(\"Base Model\")\n",
    "    axes[1, 0].set_ylabel(\"Distilled Model\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)  # Adjust for suptitle\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(\n",
    "        f\"figures/top_activations_sample_{sample_idx}.pdf\",\n",
    "        dpi=300,\n",
    "        format=\"pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "\n",
    "    # Return statistics about the activation distribution\n",
    "    return {\n",
    "        \"base_model\": {\n",
    "            \"top_neurons\": model1_top_neurons,\n",
    "            \"activations\": model1_avg_activations[model1_top_neurons].cpu().numpy(),\n",
    "            \"total_active\": len(model1_active_neurons),\n",
    "        },\n",
    "        \"distilled_model\": {\n",
    "            \"top_neurons\": model2_top_neurons,\n",
    "            \"activations\": model2_avg_activations[model2_top_neurons].cpu().numpy(),\n",
    "            \"total_active\": len(model2_active_neurons),\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Visualize top activations for a specific sample\n",
    "dataset_path = \"/data/SHARE/datasets\"  # Replace with actual dataset path\n",
    "activation_stats = visualize_top_activations(\n",
    "    sample_idx=15, dataset_path=dataset_path, threshold=0.01, top_k=5\n",
    ")\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Base Model activation summary:\")\n",
    "for i, (neuron, act) in enumerate(\n",
    "    zip(\n",
    "        activation_stats[\"base_model\"][\"top_neurons\"],\n",
    "        activation_stats[\"base_model\"][\"activations\"],\n",
    "    )\n",
    "):\n",
    "    print(f\"  #{i + 1}: Neuron {neuron} - Activation: {act:.4f}\")\n",
    "print(f\"Total active neurons: {activation_stats['base_model']['total_active']}\")\n",
    "\n",
    "print(\"\\nDistilled Model activation summary:\")\n",
    "for i, (neuron, act) in enumerate(\n",
    "    zip(\n",
    "        activation_stats[\"distilled_model\"][\"top_neurons\"],\n",
    "        activation_stats[\"distilled_model\"][\"activations\"],\n",
    "    )\n",
    "):\n",
    "    print(f\"  #{i + 1}: Neuron {neuron} - Activation: {act:.4f}\")\n",
    "print(f\"Total active neurons: {activation_stats['distilled_model']['total_active']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_top_activations(sample_idx, dataset_path, threshold=0.01, top_k=5):\n",
    "    \"\"\"\n",
    "    Visualize top activating neurons for both models on a specific sample.\n",
    "\n",
    "    Args:\n",
    "        sample_idx: Index of the sample to visualize\n",
    "        dataset_path: Path to the dataset containing images\n",
    "        threshold: Activation threshold\n",
    "        top_k: Number of top neurons to display\n",
    "    \"\"\"\n",
    "    # Get the sample\n",
    "    sample = paired_dataset[sample_idx]\n",
    "\n",
    "    # Get activations for both models\n",
    "    model1_act = sample[\"model1\"].unsqueeze(0).to(crosscoder.W_dec.device)  # Base model\n",
    "    model2_act = (\n",
    "        sample[\"model2\"].unsqueeze(0).to(crosscoder.W_dec.device)\n",
    "    )  # Distilled model\n",
    "\n",
    "    # Get timesteps\n",
    "    model1_ts = sample[\"model1_timestep\"].item()\n",
    "    model2_ts = sample[\"model2_timestep\"].item()\n",
    "\n",
    "    # Load the original image\n",
    "    img_path = os.path.join(dataset_path, sample[\"file_name\"])\n",
    "    original_img = Image.open(img_path)\n",
    "    original_img = original_img.resize((512, 512))  # Resize to consistent dimensions\n",
    "    original_img = original_img.convert(\"RGB\")  # Ensure RGB format\n",
    "\n",
    "    # Process through encoders\n",
    "    with torch.no_grad():\n",
    "        # Base model\n",
    "        model1_act_reshaped = model1_act.reshape(-1, model1_act.shape[-1])\n",
    "        model1_latents = einops.einsum(\n",
    "            model1_act_reshaped,\n",
    "            crosscoder.W_enc[0],\n",
    "            \"batch d_model, d_model d_latent -> batch d_latent\",\n",
    "        )\n",
    "        model1_latents = torch.nn.functional.relu(model1_latents + crosscoder.b_enc[0])\n",
    "\n",
    "        # Distilled model\n",
    "        model2_act_reshaped = model2_act.reshape(-1, model2_act.shape[-1])\n",
    "        model2_latents = einops.einsum(\n",
    "            model2_act_reshaped,\n",
    "            crosscoder.W_enc[1],  # Use model2 encoder weights\n",
    "            \"batch d_model, d_model d_latent -> batch d_latent\",\n",
    "        )\n",
    "        model2_latents = torch.nn.functional.relu(model2_latents + crosscoder.b_enc[1])\n",
    "\n",
    "    # Get average activation per neuron across spatial positions\n",
    "    model1_avg_activations = model1_latents.mean(dim=0)\n",
    "    model2_avg_activations = model2_latents.mean(dim=0)\n",
    "\n",
    "    # Get neurons that exceed the threshold\n",
    "    model1_active_neurons = (\n",
    "        (model1_avg_activations > threshold).nonzero().squeeze().cpu().numpy()\n",
    "    )\n",
    "    model2_active_neurons = (\n",
    "        (model2_avg_activations > threshold).nonzero().squeeze().cpu().numpy()\n",
    "    )\n",
    "\n",
    "    # Get the top_k neurons with highest activations\n",
    "    model1_top_neurons = (\n",
    "        torch.argsort(model1_avg_activations, descending=True)[:top_k].cpu().numpy()\n",
    "    )\n",
    "    model2_top_neurons = (\n",
    "        torch.argsort(model2_avg_activations, descending=True)[:top_k].cpu().numpy()\n",
    "    )\n",
    "\n",
    "    # Create a figure with 2 rows, top_k columns\n",
    "    fig, axes = plt.subplots(2, top_k, figsize=(top_k * 3, 6))\n",
    "\n",
    "    # Add title\n",
    "    fig.suptitle(\n",
    "        f\"Top {top_k} Activated Neurons for Sample {sample_idx} (Timestep Base: {model1_ts}, Distilled: {model2_ts})\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "\n",
    "    # Function to overlay activations on image using the original method\n",
    "    def plot_activation_overlay(ax, neuron_idx, model_idx, latents, activation_value):\n",
    "        # Make a copy of the original image for this subplot\n",
    "        img = original_img.copy()\n",
    "\n",
    "        # Get spatial activations for this neuron\n",
    "        spatial_dim = int(np.sqrt(latents.shape[0]))\n",
    "        spatial_activations = (\n",
    "            latents[:, neuron_idx]\n",
    "            .reshape(spatial_dim, spatial_dim)\n",
    "            .detach()\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "\n",
    "        # Normalize for visualization\n",
    "        activation_map = (spatial_activations - spatial_activations.min()) / (\n",
    "            spatial_activations.max() - spatial_activations.min() + 1e-8\n",
    "        )\n",
    "\n",
    "        # Calculate upscale factor to match image size\n",
    "        patch_size = 512 // activation_map.shape[0]\n",
    "        activation_map = np.kron(activation_map, np.ones((patch_size, patch_size)))\n",
    "\n",
    "        # Create heatmap overlay using jet colormap\n",
    "        heatmap = np.uint8(plt.cm.jet(activation_map)[..., :3] * 255)\n",
    "        heatmap = Image.fromarray(heatmap)\n",
    "\n",
    "        # Blend original image with heatmap\n",
    "        blended_img = Image.blend(img, heatmap, alpha=0.4)\n",
    "\n",
    "        # Display the blended image\n",
    "        ax.imshow(np.array(blended_img))\n",
    "\n",
    "        # Remove ticks\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        # For base model (top row), add neuron ID above\n",
    "        if model_idx == 0:\n",
    "            ax.set_title(f\"#{neuron_idx}\\n{activation_value:.2f}\", fontsize=10)\n",
    "        # For distilled model (bottom row), add neuron ID below\n",
    "        else:\n",
    "            ax.set_xlabel(f\"#{neuron_idx}\\n{activation_value:.2f}\", fontsize=10)\n",
    "\n",
    "    # Plot base model activations (top row)\n",
    "    for i in range(top_k):\n",
    "        neuron_idx = model1_top_neurons[i]\n",
    "        activation_value = model1_avg_activations[neuron_idx].item()\n",
    "        plot_activation_overlay(\n",
    "            axes[0, i], neuron_idx, 0, model1_latents, activation_value\n",
    "        )\n",
    "\n",
    "    # Plot distilled model activations (bottom row)\n",
    "    for i in range(top_k):\n",
    "        neuron_idx = model2_top_neurons[i]\n",
    "        activation_value = model2_avg_activations[neuron_idx].item()\n",
    "        plot_activation_overlay(\n",
    "            axes[1, i], neuron_idx, 1, model2_latents, activation_value\n",
    "        )\n",
    "\n",
    "    # Add row labels\n",
    "    axes[0, 0].set_ylabel(\"Base Model\", fontsize=12)\n",
    "    axes[1, 0].set_ylabel(\"Distilled Model\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)  # Adjust for suptitle\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(\n",
    "        f\"figures/top_activations_sample_{sample_idx}.pdf\",\n",
    "        dpi=300,\n",
    "        format=\"pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "\n",
    "    # Return statistics about the activation distribution\n",
    "    return {\n",
    "        \"base_model\": {\n",
    "            \"top_neurons\": model1_top_neurons,\n",
    "            \"activations\": model1_avg_activations[model1_top_neurons].cpu().numpy(),\n",
    "            \"total_active\": len(model1_active_neurons),\n",
    "        },\n",
    "        \"distilled_model\": {\n",
    "            \"top_neurons\": model2_top_neurons,\n",
    "            \"activations\": model2_avg_activations[model2_top_neurons].cpu().numpy(),\n",
    "            \"total_active\": len(model2_active_neurons),\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Visualize top activations for a specific sample\n",
    "dataset_path = \"/path/to/your/dataset\"  # Replace with actual dataset path\n",
    "activation_stats = visualize_top_activations(\n",
    "    sample_idx=42, dataset_path=dataset_path, threshold=0.01, top_k=5\n",
    ")\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Base Model activation summary:\")\n",
    "for i, (neuron, act) in enumerate(\n",
    "    zip(\n",
    "        activation_stats[\"base_model\"][\"top_neurons\"],\n",
    "        activation_stats[\"base_model\"][\"activations\"],\n",
    "    )\n",
    "):\n",
    "    print(f\"  #{i + 1}: Neuron {neuron} - Activation: {act:.4f}\")\n",
    "print(f\"Total active neurons: {activation_stats['base_model']['total_active']}\")\n",
    "\n",
    "print(\"\\nDistilled Model activation summary:\")\n",
    "for i, (neuron, act) in enumerate(\n",
    "    zip(\n",
    "        activation_stats[\"distilled_model\"][\"top_neurons\"],\n",
    "        activation_stats[\"distilled_model\"][\"activations\"],\n",
    "    )\n",
    "):\n",
    "    print(f\"  #{i + 1}: Neuron {neuron} - Activation: {act:.4f}\")\n",
    "print(f\"Total active neurons: {activation_stats['distilled_model']['total_active']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate reconstruction error of distilled model on its own data by timestep\n",
    "def calculate_distilled_error_by_timestep():\n",
    "    results = {}\n",
    "\n",
    "    # Create dataloader for distilled model dataset\n",
    "    distilled_dl = torch.utils.data.DataLoader(\n",
    "        model2_dataset, batch_size=16, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "    # Initialize counters for each timestep\n",
    "    timestep_errors = {\n",
    "        int(ts): {\"total_mse\": 0.0, \"total_samples\": 0} for ts in timestep_map\n",
    "    }\n",
    "\n",
    "    # Get weights for distilled model\n",
    "    W_enc = crosscoder.W_enc[1]\n",
    "    b_enc = crosscoder.b_enc\n",
    "    W_dec = crosscoder.W_dec[:, 1, :]\n",
    "    norm_scaling_factor = paired_dataset.norm_scaling_factors[1]\n",
    "\n",
    "    # Process all samples\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(\n",
    "            distilled_dl, desc=\"Computing reconstruction error by timestep\"\n",
    "        ):\n",
    "            acts = batch[\"activations\"].to(crosscoder.W_dec.device)\n",
    "            timesteps = batch[\"timestep\"]\n",
    "\n",
    "            # Process each sample\n",
    "            for i in range(acts.shape[0]):\n",
    "                act = acts[i].unsqueeze(0)  # Add batch dimension\n",
    "                ts = int(timesteps[i].item())\n",
    "\n",
    "                if ts not in timestep_errors:\n",
    "                    continue\n",
    "\n",
    "                # Reshape and normalize\n",
    "                act = einops.rearrange(\n",
    "                    act,\n",
    "                    \"batch sample_size d_model -> (batch sample_size) d_model\",\n",
    "                )\n",
    "                act = act * norm_scaling_factor\n",
    "\n",
    "                # Forward through encoder to get latent activations\n",
    "                latents = einops.einsum(\n",
    "                    act,\n",
    "                    W_enc,\n",
    "                    \"batch d_model, d_model d_latent -> batch d_latent\",\n",
    "                )\n",
    "                latents = torch.nn.functional.relu(latents + b_enc)\n",
    "\n",
    "                # Forward through decoder to reconstruct\n",
    "                reconstructed = einops.einsum(\n",
    "                    latents,\n",
    "                    W_dec,\n",
    "                    \"batch d_latent, d_latent d_model -> batch d_model\",\n",
    "                )\n",
    "\n",
    "                # Calculate MSE\n",
    "                mse = torch.nn.functional.mse_loss(reconstructed, act)\n",
    "\n",
    "                # Update counters\n",
    "                timestep_errors[ts][\"total_mse\"] += mse.item() * act.shape[0]\n",
    "                timestep_errors[ts][\"total_samples\"] += act.shape[0]\n",
    "\n",
    "    # Calculate average MSE for each timestep\n",
    "    for ts in timestep_errors:\n",
    "        if timestep_errors[ts][\"total_samples\"] > 0:\n",
    "            avg_mse = (\n",
    "                timestep_errors[ts][\"total_mse\"] / timestep_errors[ts][\"total_samples\"]\n",
    "            )\n",
    "            results[ts] = {\n",
    "                \"mse\": avg_mse,\n",
    "                \"samples\": timestep_errors[ts][\"total_samples\"],\n",
    "            }\n",
    "            print(\n",
    "                f\"Timestep {ts}: MSE = {avg_mse:.6f}, Samples = {timestep_errors[ts]['total_samples']}\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"No samples found for timestep {ts}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Calculate reconstruction errors by timestep\n",
    "distilled_errors = calculate_distilled_error_by_timestep()\n",
    "\n",
    "# Create a bar plot of the errors\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "timesteps = list(distilled_errors.keys())\n",
    "errors = [distilled_errors[ts][\"mse\"] for ts in timesteps]\n",
    "samples = [distilled_errors[ts][\"samples\"] for ts in timesteps]\n",
    "\n",
    "# Create the bar plot\n",
    "bars = plt.bar(range(len(timesteps)), errors, color=colors[2], alpha=0.8)\n",
    "\n",
    "# Add sample count as text on each bar\n",
    "for i, bar in enumerate(bars):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 0.001,\n",
    "        f\"n={samples[i]}\",\n",
    "        ha=\"center\",\n",
    "        fontsize=9,\n",
    "    )\n",
    "\n",
    "plt.title(\"Reconstruction Error of Distilled Model by Timestep\")\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xticks(range(len(timesteps)), [f\"{ts}\" for ts in timesteps])\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\n",
    "    \"figures/distilled_error_by_timestep.pdf\",\n",
    "    dpi=300,\n",
    "    format=\"pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "\n",
    "# Also create a version with error bars representing standard deviation\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Calculate standard deviations by timestep (we'll need to run another pass over the data)\n",
    "timestep_stds = {int(ts): {\"errors\": [], \"total_samples\": 0} for ts in timestep_map}\n",
    "distilled_dl = torch.utils.data.DataLoader(\n",
    "    model2_dataset, batch_size=16, shuffle=False, num_workers=4\n",
    ")\n",
    "norm_scaling_factor = paired_dataset.norm_scaling_factors[1]\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(distilled_dl, desc=\"Computing error standard deviations\"):\n",
    "        acts = batch[\"activations\"].to(crosscoder.W_dec.device)\n",
    "        timesteps = batch[\"timestep\"]\n",
    "\n",
    "        # Process each sample\n",
    "        for i in range(acts.shape[0]):\n",
    "            act = acts[i].unsqueeze(0)  # Add batch dimension\n",
    "            ts = int(timesteps[i].item())\n",
    "\n",
    "            if ts not in timestep_stds:\n",
    "                continue\n",
    "\n",
    "            # Reshape and normalize\n",
    "            act = einops.rearrange(\n",
    "                act,\n",
    "                \"batch sample_size d_model -> (batch sample_size) d_model\",\n",
    "            )\n",
    "            act = act * norm_scaling_factor\n",
    "\n",
    "            # Forward through encoder to get latent activations\n",
    "            latents = einops.einsum(\n",
    "                act,\n",
    "                crosscoder.W_enc[1],\n",
    "                \"batch d_model, d_model d_latent -> batch d_latent\",\n",
    "            )\n",
    "            latents = torch.nn.functional.relu(latents + crosscoder.b_enc[1])\n",
    "\n",
    "            # Forward through decoder to reconstruct\n",
    "            reconstructed = einops.einsum(\n",
    "                latents,\n",
    "                crosscoder.W_dec[:, 1, :],\n",
    "                \"batch d_latent, d_latent d_model -> batch d_model\",\n",
    "            )\n",
    "\n",
    "            # Calculate MSE\n",
    "            mse = torch.nn.functional.mse_loss(reconstructed, act)\n",
    "\n",
    "            # Store individual errors\n",
    "            timestep_stds[ts][\"errors\"].append(mse.item())\n",
    "            timestep_stds[ts][\"total_samples\"] += 1\n",
    "\n",
    "# Calculate standard deviations\n",
    "error_stds = []\n",
    "for ts in timesteps:\n",
    "    if timestep_stds[ts][\"total_samples\"] > 0:\n",
    "        std = np.std(timestep_stds[ts][\"errors\"])\n",
    "        error_stds.append(std)\n",
    "    else:\n",
    "        error_stds.append(0)\n",
    "\n",
    "# Create bar plot with error bars\n",
    "plt.bar(\n",
    "    range(len(timesteps)),\n",
    "    errors,\n",
    "    yerr=error_stds,\n",
    "    color=colors[2],\n",
    "    alpha=0.8,\n",
    "    ecolor=\"black\",\n",
    "    capsize=5,\n",
    ")\n",
    "\n",
    "plt.title(\n",
    "    \"Reconstruction Error of Distilled Model by Timestep (with Standard Deviation)\"\n",
    ")\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xticks(range(len(timesteps)), [f\"{ts}\" for ts in timesteps])\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\n",
    "    \"figures/distilled_error_by_timestep_with_std.pdf\",\n",
    "    dpi=300,\n",
    "    format=\"pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average norms per timestep for both datasets using batches\n",
    "def compute_norms_by_timestep(batch_size=32):\n",
    "    print(\"Computing norms by timestep...\")\n",
    "\n",
    "    # Dictionaries to store results\n",
    "    model1_norms_by_timestep = {int(ts): [] for ts in timestep_map}\n",
    "    model2_norms_by_timestep = {int(ts): [] for ts in timestep_map}\n",
    "\n",
    "    # For calculating variance\n",
    "    model1_acts_by_timestep = {int(ts): [] for ts in timestep_map}\n",
    "    model2_acts_by_timestep = {int(ts): [] for ts in timestep_map}\n",
    "\n",
    "    # Create dataloaders for batch processing\n",
    "    model1_loader = torch.utils.data.DataLoader(\n",
    "        model1_dataset, batch_size=batch_size, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "    model2_loader = torch.utils.data.DataLoader(\n",
    "        model2_dataset, batch_size=batch_size, shuffle=False, num_workers=4\n",
    "    )\n",
    "\n",
    "    # Process model1 dataset in batches\n",
    "    print(\"Processing base model dataset...\")\n",
    "    for batch in tqdm(model1_loader, desc=\"Base model\"):\n",
    "        acts = batch[\"activations\"]\n",
    "        timesteps = batch[\"timestep\"]\n",
    "\n",
    "        # Process each sample in the batch\n",
    "        for i in range(acts.shape[0]):\n",
    "            ts = int(timesteps[i].item())\n",
    "\n",
    "            if ts in model1_norms_by_timestep:\n",
    "                act = acts[i]\n",
    "                norm = torch.norm(act, dim=-1).mean().item()\n",
    "                model1_norms_by_timestep[ts].append(norm)\n",
    "                model1_acts_by_timestep[ts].append(act)\n",
    "\n",
    "    # Process model2 dataset in batches\n",
    "    print(\"Processing distilled model dataset...\")\n",
    "    for batch in tqdm(model2_loader, desc=\"Distilled model\"):\n",
    "        acts = batch[\"activations\"]\n",
    "        timesteps = batch[\"timestep\"]\n",
    "\n",
    "        # Process each sample in the batch\n",
    "        for i in range(acts.shape[0]):\n",
    "            ts = int(timesteps[i].item())\n",
    "\n",
    "            if ts in model2_norms_by_timestep:\n",
    "                act = acts[i]\n",
    "                norm = torch.norm(act, dim=-1).mean().item()\n",
    "                model2_norms_by_timestep[ts].append(norm)\n",
    "                model2_acts_by_timestep[ts].append(act)\n",
    "\n",
    "    # Compute variance for model1 by timestep\n",
    "    print(\"Computing variances...\")\n",
    "    model1_variance_by_timestep = {}\n",
    "    for ts in tqdm(model1_acts_by_timestep, desc=\"Base model variance\"):\n",
    "        if len(model1_acts_by_timestep[ts]) > 0:\n",
    "            # Stack activations for this timestep - limit to 1000 samples if more available\n",
    "            samples = model1_acts_by_timestep[ts]\n",
    "            if len(samples) > 1000:\n",
    "                samples = random.sample(samples, 1000)\n",
    "\n",
    "            acts_tensor = torch.stack(samples)\n",
    "\n",
    "            # Calculate mean and variance\n",
    "            mean = acts_tensor.mean(0)\n",
    "            variance = (acts_tensor - mean).pow(2).sum(-1).mean().item()\n",
    "\n",
    "            model1_variance_by_timestep[ts] = variance\n",
    "        else:\n",
    "            model1_variance_by_timestep[ts] = None\n",
    "\n",
    "    # Compute variance for model2 by timestep\n",
    "    model2_variance_by_timestep = {}\n",
    "    for ts in tqdm(model2_acts_by_timestep, desc=\"Distilled model variance\"):\n",
    "        if len(model2_acts_by_timestep[ts]) > 0:\n",
    "            # Stack activations for this timestep - limit to 1000 samples if more available\n",
    "            samples = model2_acts_by_timestep[ts]\n",
    "            if len(samples) > 1000:\n",
    "                samples = random.sample(samples, 1000)\n",
    "\n",
    "            acts_tensor = torch.stack(samples)\n",
    "\n",
    "            # Calculate mean and variance\n",
    "            mean = acts_tensor.mean(0)\n",
    "            variance = (acts_tensor - mean).pow(2).sum(-1).mean().item()\n",
    "\n",
    "            model2_variance_by_timestep[ts] = variance\n",
    "        else:\n",
    "            model2_variance_by_timestep[ts] = None\n",
    "\n",
    "    # Calculate average norms for each timestep\n",
    "    model1_avg_norms = {}\n",
    "    model2_avg_norms = {}\n",
    "\n",
    "    for ts in model1_norms_by_timestep:\n",
    "        if len(model1_norms_by_timestep[ts]) > 0:\n",
    "            model1_avg_norms[ts] = np.mean(model1_norms_by_timestep[ts])\n",
    "        else:\n",
    "            print(f\"No samples for model1, timestep {ts}\")\n",
    "            model1_avg_norms[ts] = 0\n",
    "\n",
    "    for ts in model2_norms_by_timestep:\n",
    "        if len(model2_norms_by_timestep[ts]) > 0:\n",
    "            model2_avg_norms[ts] = np.mean(model2_norms_by_timestep[ts])\n",
    "        else:\n",
    "            print(f\"No samples for model2, timestep {ts}\")\n",
    "            model2_avg_norms[ts] = 0\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\nBase Model (Model 1) average norms by timestep:\")\n",
    "    for ts in sorted(model1_avg_norms.keys()):\n",
    "        if model1_variance_by_timestep[ts] is not None:\n",
    "            print(\n",
    "                f\"  Timestep {ts}: Avg Norm = {model1_avg_norms[ts]:.4f}, Variance = {model1_variance_by_timestep[ts]:.4f}, Samples = {len(model1_norms_by_timestep[ts])}\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"  Timestep {ts}: Avg Norm = {model1_avg_norms[ts]:.4f}, Variance = N/A, Samples = {len(model1_norms_by_timestep[ts])}\"\n",
    "            )\n",
    "\n",
    "    print(\"\\nDistilled Model (Model 2) average norms by timestep:\")\n",
    "    for ts in sorted(model2_avg_norms.keys()):\n",
    "        if model2_variance_by_timestep[ts] is not None:\n",
    "            print(\n",
    "                f\"  Timestep {ts}: Avg Norm = {model2_avg_norms[ts]:.4f}, Variance = {model2_variance_by_timestep[ts]:.4f}, Samples = {len(model2_norms_by_timestep[ts])}\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"  Timestep {ts}: Avg Norm = {model2_avg_norms[ts]:.4f}, Variance = N/A, Samples = {len(model2_norms_by_timestep[ts])}\"\n",
    "            )\n",
    "\n",
    "    # Calculate target norm (as in the original code)\n",
    "    d_model = model1_dataset[0][\"activations\"].shape[-1]\n",
    "    target_norm = torch.sqrt(torch.tensor(d_model)).item()\n",
    "    print(f\"\\nTarget norm: {target_norm:.4f}\")\n",
    "\n",
    "    # Calculate scaling factors for each timestep\n",
    "    model1_scaling_factors = {\n",
    "        ts: target_norm / norm if norm > 0 else 0\n",
    "        for ts, norm in model1_avg_norms.items()\n",
    "    }\n",
    "    model2_scaling_factors = {\n",
    "        ts: target_norm / norm if norm > 0 else 0\n",
    "        for ts, norm in model2_avg_norms.items()\n",
    "    }\n",
    "\n",
    "    print(\"\\nScaling factors by timestep:\")\n",
    "    for ts in sorted(model1_scaling_factors.keys()):\n",
    "        print(\n",
    "            f\"  Timestep {ts}: Model1 = {model1_scaling_factors[ts]:.4f}, Model2 = {model2_scaling_factors[ts]:.4f}\"\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"model1_norms\": model1_avg_norms,\n",
    "        \"model2_norms\": model2_avg_norms,\n",
    "        \"model1_variance\": model1_variance_by_timestep,\n",
    "        \"model2_variance\": model2_variance_by_timestep,\n",
    "        \"target_norm\": target_norm,\n",
    "        \"model1_samples\": {\n",
    "            ts: len(model1_norms_by_timestep[ts]) for ts in model1_norms_by_timestep\n",
    "        },\n",
    "        \"model2_samples\": {\n",
    "            ts: len(model2_norms_by_timestep[ts]) for ts in model2_norms_by_timestep\n",
    "        },\n",
    "        \"model1_scaling_factors\": model1_scaling_factors,\n",
    "        \"model2_scaling_factors\": model2_scaling_factors,\n",
    "    }\n",
    "\n",
    "\n",
    "# Import random for sampling in variance calculation\n",
    "import random\n",
    "\n",
    "# Calculate norms by timestep\n",
    "norm_results = compute_norms_by_timestep(batch_size=64)\n",
    "\n",
    "# Create a bar plot comparing norms by timestep\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "timesteps = sorted(norm_results[\"model1_norms\"].keys())\n",
    "model1_norms = [norm_results[\"model1_norms\"][ts] for ts in timesteps]\n",
    "model2_norms = [norm_results[\"model2_norms\"][ts] for ts in timesteps]\n",
    "\n",
    "# Set positions for the bars\n",
    "bar_width = 0.35\n",
    "x_positions = np.arange(len(timesteps))\n",
    "\n",
    "# Create grouped bars for both models\n",
    "bars1 = plt.bar(\n",
    "    x_positions - bar_width / 2,\n",
    "    model1_norms,\n",
    "    bar_width,\n",
    "    label=\"Base Model\",\n",
    "    color=colors[0],\n",
    ")\n",
    "\n",
    "bars2 = plt.bar(\n",
    "    x_positions + bar_width / 2,\n",
    "    model2_norms,\n",
    "    bar_width,\n",
    "    label=\"Distilled Model\",\n",
    "    color=colors[2],\n",
    ")\n",
    "\n",
    "# Add a horizontal line for the target norm\n",
    "plt.axhline(\n",
    "    y=norm_results[\"target_norm\"],\n",
    "    color=\"k\",\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.5,\n",
    "    label=f\"Target Norm ({norm_results['target_norm']:.2f})\",\n",
    ")\n",
    "\n",
    "# Add sample counts as text\n",
    "for i, (ts, count) in enumerate(norm_results[\"model1_samples\"].items()):\n",
    "    if ts in timesteps:\n",
    "        idx = timesteps.index(ts)\n",
    "        plt.text(\n",
    "            x_positions[idx] - bar_width / 2,\n",
    "            model1_norms[idx] + 0.5,\n",
    "            f\"n={count}\",\n",
    "            ha=\"center\",\n",
    "            fontsize=8,\n",
    "            rotation=45,\n",
    "        )\n",
    "\n",
    "for i, (ts, count) in enumerate(norm_results[\"model2_samples\"].items()):\n",
    "    if ts in timesteps:\n",
    "        idx = timesteps.index(ts)\n",
    "        plt.text(\n",
    "            x_positions[idx] + bar_width / 2,\n",
    "            model2_norms[idx] + 0.5,\n",
    "            f\"n={count}\",\n",
    "            ha=\"center\",\n",
    "            fontsize=8,\n",
    "            rotation=45,\n",
    "        )\n",
    "\n",
    "plt.title(\"Average Activation Norms by Timestep\")\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"Average Norm\")\n",
    "plt.xticks(x_positions, [f\"{ts}\" for ts in timesteps])\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\n",
    "    \"figures/activation_norms_by_timestep.pdf\",\n",
    "    dpi=300,\n",
    "    format=\"pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "\n",
    "# Also create a bar plot for the variances\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "model1_variances = [\n",
    "    norm_results[\"model1_variance\"][ts]\n",
    "    if norm_results[\"model1_variance\"][ts] is not None\n",
    "    else 0\n",
    "    for ts in timesteps\n",
    "]\n",
    "model2_variances = [\n",
    "    norm_results[\"model2_variance\"][ts]\n",
    "    if norm_results[\"model2_variance\"][ts] is not None\n",
    "    else 0\n",
    "    for ts in timesteps\n",
    "]\n",
    "\n",
    "# Create grouped bars for variances\n",
    "bars1 = plt.bar(\n",
    "    x_positions - bar_width / 2,\n",
    "    model1_variances,\n",
    "    bar_width,\n",
    "    label=\"Base Model\",\n",
    "    color=colors[0],\n",
    ")\n",
    "\n",
    "bars2 = plt.bar(\n",
    "    x_positions + bar_width / 2,\n",
    "    model2_variances,\n",
    "    bar_width,\n",
    "    label=\"Distilled Model\",\n",
    "    color=colors[2],\n",
    ")\n",
    "\n",
    "plt.title(\"Activation Variances by Timestep\")\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"Variance\")\n",
    "plt.xticks(x_positions, [f\"{ts}\" for ts in timesteps])\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\n",
    "    \"figures/activation_variances_by_timestep.pdf\",\n",
    "    dpi=300,\n",
    "    format=\"pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "\n",
    "# Calculate and plot norm ratios\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "norm_ratios = [\n",
    "    model1_norms[i] / model2_norms[i] if model2_norms[i] > 0 else 0\n",
    "    for i in range(len(timesteps))\n",
    "]\n",
    "\n",
    "plt.bar(x_positions, norm_ratios, color=colors[1])\n",
    "plt.axhline(y=1.0, color=\"k\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "plt.title(\"Ratio of Base Model Norm to Distilled Model Norm by Timestep\")\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"Norm Ratio (Base/Distilled)\")\n",
    "plt.xticks(x_positions, [f\"{ts}\" for ts in timesteps])\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\n",
    "    \"figures/norm_ratios_by_timestep.pdf\", dpi=300, format=\"pdf\", bbox_inches=\"tight\"\n",
    ")\n",
    "\n",
    "# Create a plot for the scaling factors\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "model1_scaling = [norm_results[\"model1_scaling_factors\"][ts] for ts in timesteps]\n",
    "model2_scaling = [norm_results[\"model2_scaling_factors\"][ts] for ts in timesteps]\n",
    "\n",
    "# Create grouped bars\n",
    "bars1 = plt.bar(\n",
    "    x_positions - bar_width / 2,\n",
    "    model1_scaling,\n",
    "    bar_width,\n",
    "    label=\"Base Model\",\n",
    "    color=colors[0],\n",
    ")\n",
    "\n",
    "bars2 = plt.bar(\n",
    "    x_positions + bar_width / 2,\n",
    "    model2_scaling,\n",
    "    bar_width,\n",
    "    label=\"Distilled Model\",\n",
    "    color=colors[2],\n",
    ")\n",
    "\n",
    "plt.title(\"Scaling Factors by Timestep\")\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"Scaling Factor\")\n",
    "plt.xticks(x_positions, [f\"{ts}\" for ts in timesteps])\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\n",
    "    \"figures/scaling_factors_by_timestep.pdf\",\n",
    "    dpi=300,\n",
    "    format=\"pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

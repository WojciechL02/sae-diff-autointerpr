{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import torch\n",
    "from diffusers import DiffusionPipeline\n",
    "from src.hooked_model.hooked_model_sdxl import HookedDiffusionModel\n",
    "import matplotlib.pyplot as plt\n",
    "import einops\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch._inductor.config.conv_1x1_as_mm = True\n",
    "torch._inductor.config.coordinate_descent_tuning = True\n",
    "torch._inductor.config.epilogue_fusion = False\n",
    "torch._inductor.config.coordinate_descent_check_all_directions = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare SDXL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  3.67it/s]\n"
     ]
    }
   ],
   "source": [
    "pipe_sd_turbo = DiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\"\n",
    ").to(\"cuda\")\n",
    "\n",
    "hooked_model = HookedDiffusionModel(\n",
    "    model=pipe_sd_turbo.unet,\n",
    "    scheduler=pipe_sd_turbo.scheduler,\n",
    "    encode_prompt=pipe_sd_turbo.encode_prompt,\n",
    "    vae=pipe_sd_turbo.vae,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float16\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cuda\"\n",
    "ckpt_path = (\n",
    "    \"sae-diff-autointerpr/checkpoints/batch_topk_expansion_factor16_k32_multi_topkFalse_auxk_alpha0.03125_output_249_output\"\n",
    ")\n",
    "hookpoint = \"down_blocks.2\"\n",
    "\n",
    "from src.sae.sae import Sae\n",
    "\n",
    "sae = Sae.load_from_disk(\n",
    "\tos.path.join(\n",
    "\t\tckpt_path,\n",
    "\t\thookpoint,\n",
    "\t),\n",
    "\tdevice=device,\n",
    ").to(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare activations dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps = 4\n",
    "activations_dataset_path = f\"sae-diff-autointerpr/activations/activations/sdxl-turbo/steps{num_timesteps}\"\n",
    "activations_dataset = Dataset.load_from_disk(\n",
    "\tos.path.join(activations_dataset_path, hookpoint), keep_in_memory=False\n",
    ")\n",
    "activations_dataset.set_format(\n",
    "\ttype=\"torch\", columns=[\"activations\", \"timestep\", \"file_name\"], dtype=dtype\n",
    ")\n",
    "activations_dataset = activations_dataset.filter(\n",
    "\tlambda x: x[\"timestep\"] == 249, batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:16<00:00, 19.50it/s]\n"
     ]
    }
   ],
   "source": [
    "avg_activations_per_sample = torch.zeros(\n",
    "\t(len(activations_dataset), sae.num_latents), dtype=torch.float16\n",
    ")\n",
    "\n",
    "batch_size = 16\n",
    "dl = torch.utils.data.DataLoader(\n",
    "\tactivations_dataset, batch_size=batch_size, shuffle=False, num_workers=4\n",
    ")\n",
    "with torch.no_grad():\n",
    "\tfor i, batch in tqdm(enumerate(dl), total=len(dl)):\n",
    "\t\tacts = batch[\"activations\"].to(sae.device)\n",
    "\t\tacts = einops.rearrange(\n",
    "\t\t\tacts,\n",
    "\t\t\t\"batch sample_size d_model -> (batch sample_size) d_model\",\n",
    "\t\t)\n",
    "\t\tout = sae.pre_acts(acts)\n",
    "\t\t# Reshape to get per-sample activations and compute mean for each sample\n",
    "\t\tout = out.view(\n",
    "\t\t\tbatch[\"activations\"].shape[0], -1, sae.num_latents\n",
    "\t\t)  # [batch, sample_size, num_latents]\n",
    "\t\tbatch_avg_activations = out.mean(dim=1).to(\n",
    "\t\t\tdtype=torch.float16\n",
    "\t\t)  # [batch, num_latents]\n",
    "\n",
    "\t\t# Store in the correct indices\n",
    "\t\tstart_idx = i * batch_size\n",
    "\t\tend_idx = min(start_idx + batch_size, len(activations_dataset))\n",
    "\t\tavg_activations_per_sample[start_idx:end_idx] = batch_avg_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_topk_activating_examples(activations_per_sample, latent_idx, k=10):\n",
    "\ttopk_indices = torch.argsort(\n",
    "\t\tactivations_per_sample[:, latent_idx], dim=0, descending=True\n",
    "\t)[:k]\n",
    "\treturn topk_indices\n",
    "\n",
    "\n",
    "k = 5\n",
    "latent_idx = 374\n",
    "\n",
    "topk_indices = find_topk_activating_examples(\n",
    "    avg_activations_per_sample, latent_idx, k\n",
    ")  # find topk samples containing patches with higest activations\n",
    "topk_samples = activations_dataset[topk_indices.tolist()]\n",
    "sae_latents = []\n",
    "activations = topk_samples[\"activations\"].to(sae.device)\n",
    "timesteps = topk_samples[\"timestep\"]\n",
    "file_names_topk = topk_samples[\"file_name\"]\n",
    "activations = einops.rearrange(\n",
    "    activations,\n",
    "    \"batch sample_size d_model -> (batch sample_size) d_model\",\n",
    ")\n",
    "out = sae.pre_acts(activations)\n",
    "sae_latents = out.view(k, -1, sae.num_latents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take only captions corresponding to the selected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/net/pr2/projects/plgrid/plggzzsn2025/coco/annotations/captions_val2017.json\", \"r\") as f:\n",
    "    captions = json.load(f)\n",
    "\n",
    "ids = [int(os.path.splitext(name.split(\"/\")[1])[0]) for name in file_names_topk]\n",
    "captions = [item['caption'] for item in captions[\"annotations\"] if item['image_id'] in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.34 GiB. GPU 0 has a total capacity of 39.67 GiB of which 695.44 MiB is free. Process 1519631 has 12.20 GiB memory in use. Process 1522245 has 9.23 GiB memory in use. Including non-PyTorch memory, this process has 17.56 GiB memory in use. Of the allocated memory 16.28 GiB is allocated by PyTorch, and 797.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(captions), bsz):\n\u001b[32m      7\u001b[39m \tend_idx = \u001b[38;5;28mmin\u001b[39m(i + bsz, \u001b[38;5;28mlen\u001b[39m(captions))\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \t_, cache_dict = \u001b[43mhooked_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m\t\t\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcaptions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m\t\t\u001b[49m\u001b[43mnum_images_per_prompt\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m\t\t\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m\t\t\u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m\t\t\u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m249\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m\t\t\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m640\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m\t\t\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m480\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m\t\t\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m\t\t\u001b[49m\u001b[43mpositions_to_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdown_blocks.2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m\t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \tacts = cache_dict[\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mdown_blocks.2\u001b[39m\u001b[33m\"\u001b[39m][:, -\u001b[32m1\u001b[39m]\n\u001b[32m     20\u001b[39m \tacts = einops.rearrange(\n\u001b[32m     21\u001b[39m \t\tacts,\n\u001b[32m     22\u001b[39m \t\t\u001b[33m\"\u001b[39m\u001b[33mbatch sample_size d_model -> (batch sample_size) d_model\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m \t)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/projects/sae-diff-autointerpr/src/hooked_model/hooked_model_sdxl.py:329\u001b[39m, in \u001b[36mHookedDiffusionModel.run_with_cache\u001b[39m\u001b[34m(self, positions_to_cache, save_input, save_output, unconditional, device, guidance_scale, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m hooks = [\n\u001b[32m    318\u001b[39m     \u001b[38;5;28mself\u001b[39m._register_cache_hook(\n\u001b[32m    319\u001b[39m         position,\n\u001b[32m   (...)\u001b[39m\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m position \u001b[38;5;129;01min\u001b[39;00m positions_to_cache\n\u001b[32m    326\u001b[39m ]\n\u001b[32m    327\u001b[39m hooks = [hook \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m hooks \u001b[38;5;28;01mif\u001b[39;00m hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m image = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[38;5;66;03m# Stack cached tensors along time dimension\u001b[39;00m\n\u001b[32m    336\u001b[39m cache_dict = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/projects/sae-diff-autointerpr/src/hooked_model/hooked_model_sdxl.py:208\u001b[39m, in \u001b[36mHookedDiffusionModel.__call__\u001b[39m\u001b[34m(self, prompt, prompt_2, height, width, num_inference_steps, timesteps, sigmas, guidance_scale, negative_prompt, negative_prompt_2, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, pooled_prompt_embeds, negative_pooled_prompt_embeds, output_type, device, **kwargs)\u001b[39m\n\u001b[32m    197\u001b[39m latents = \u001b[38;5;28mself\u001b[39m._denoise_loop(\n\u001b[32m    198\u001b[39m     timesteps,\n\u001b[32m    199\u001b[39m     latents,\n\u001b[32m   (...)\u001b[39m\u001b[32m    204\u001b[39m     extra_step_kwargs,\n\u001b[32m    205\u001b[39m )\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# Convert latents to final image\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m image = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_postprocess_latents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/projects/sae-diff-autointerpr/src/hooked_model/hooked_model_sdxl.py:492\u001b[39m, in \u001b[36mHookedDiffusionModel._postprocess_latents\u001b[39m\u001b[34m(self, latents, output_type, generator)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    491\u001b[39m     latents = latents / \u001b[38;5;28mself\u001b[39m.vae.config.scaling_factor\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m image = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvae\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlatents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# cast back to fp16 if needed\u001b[39;00m\n\u001b[32m    497\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m needs_upcasting:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/diffusers/utils/accelerate_utils.py:46\u001b[39m, in \u001b[36mapply_forward_hook.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_hf_hook\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._hf_hook, \u001b[33m\"\u001b[39m\u001b[33mpre_forward\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     45\u001b[39m     \u001b[38;5;28mself\u001b[39m._hf_hook.pre_forward(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/diffusers/models/autoencoders/autoencoder_kl.py:327\u001b[39m, in \u001b[36mAutoencoderKL.decode\u001b[39m\u001b[34m(self, z, return_dict, generator)\u001b[39m\n\u001b[32m    325\u001b[39m     decoded = torch.cat(decoded_slices)\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     decoded = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m.sample\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (decoded,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/diffusers/models/autoencoders/autoencoder_kl.py:298\u001b[39m, in \u001b[36mAutoencoderKL._decode\u001b[39m\u001b[34m(self, z, return_dict)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.post_quant_conv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    296\u001b[39m     z = \u001b[38;5;28mself\u001b[39m.post_quant_conv(z)\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m dec = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (dec,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/diffusers/models/autoencoders/vae.py:350\u001b[39m, in \u001b[36mDecoder.forward\u001b[39m\u001b[34m(self, sample, latent_embeds)\u001b[39m\n\u001b[32m    348\u001b[39m     \u001b[38;5;66;03m# up\u001b[39;00m\n\u001b[32m    349\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m up_block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.up_blocks:\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m         sample = \u001b[43mup_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_embeds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# post-process\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m latent_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/diffusers/models/unets/unet_2d_blocks.py:2817\u001b[39m, in \u001b[36mUpDecoderBlock2D.forward\u001b[39m\u001b[34m(self, hidden_states, temb)\u001b[39m\n\u001b[32m   2815\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.upsamplers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2816\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m upsampler \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.upsamplers:\n\u001b[32m-> \u001b[39m\u001b[32m2817\u001b[39m         hidden_states = \u001b[43mupsampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2819\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/diffusers/models/upsampling.py:188\u001b[39m, in \u001b[36mUpsample2D.forward\u001b[39m\u001b[34m(self, hidden_states, output_size, *args, **kwargs)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_conv:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name == \u001b[33m\"\u001b[39m\u001b[33mconv\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m         hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    190\u001b[39m         hidden_states = \u001b[38;5;28mself\u001b[39m.Conv2d_0(hidden_states)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/plgwlapacz/conda_envs/zzsn/lib/python3.11/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 2.34 GiB. GPU 0 has a total capacity of 39.67 GiB of which 695.44 MiB is free. Process 1519631 has 12.20 GiB memory in use. Process 1522245 has 9.23 GiB memory in use. Including non-PyTorch memory, this process has 17.56 GiB memory in use. Of the allocated memory 16.28 GiB is allocated by PyTorch, and 797.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "new_avg_activations_per_sample = torch.zeros(\n",
    "\t(len(activations_dataset), sae.num_latents), dtype=torch.float16\n",
    ")\n",
    "bsz = 16\n",
    "with torch.no_grad():\n",
    "\tfor i in range(0, len(captions), bsz):\n",
    "\t\tend_idx = min(i + bsz, len(captions))\n",
    "\t\t_, cache_dict = hooked_model.run_with_cache(\n",
    "\t\t\tprompt=captions[i:end_idx],\n",
    "\t\t\tnum_images_per_prompt=1,\n",
    "\t\t\tdevice=\"cuda\",\n",
    "\t\t\tguidance_scale=7.5,\n",
    "\t\t\tnum_inference_steps=249,\n",
    "\t\t\theight=640,\n",
    "\t\t\twidth=480,\n",
    "\t\t\tgenerator=torch.Generator(device=\"cuda\").manual_seed(1),\n",
    "\t\t\tpositions_to_cache=[\"down_blocks.2\"],\n",
    "\t\t)\n",
    "\t\tacts = cache_dict[\"output\"][\"down_blocks.2\"][:, -1]\n",
    "\t\tacts = einops.rearrange(\n",
    "\t\t\tacts,\n",
    "\t\t\t\"batch sample_size d_model -> (batch sample_size) d_model\",\n",
    "\t\t)\n",
    "\t\tout = sae.pre_acts(acts)\n",
    "\t\t# Reshape to get per-sample activations and compute mean for each sample\n",
    "\t\tout = out.view(\n",
    "\t\t\tbatch[\"activations\"].shape[0], -1, sae.num_latents\n",
    "\t\t)  # [batch, sample_size, num_latents]\n",
    "\t\tbatch_avg_activations = out.mean(dim=1).to(\n",
    "\t\t\tdtype=torch.float16\n",
    "\t\t)  # [batch, num_latents]\n",
    "\n",
    "\t\tstart_idx = i\n",
    "\t\tnew_avg_activations_per_sample[start_idx:end_idx] = batch_avg_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_activations = avg_activations_per_sample[topk_indices.tolist()].mean(dim=0).cpu().numpy()\n",
    "new_avg_activations = new_avg_activations_per_sample.mean(dim=0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_activations_per_sample[topk_indices.tolist()].shape, new_avg_activations_per_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
